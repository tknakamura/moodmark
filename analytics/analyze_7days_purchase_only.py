#!/usr/bin/env python3
"""
ç›´è¿‘7æ—¥é–“ã®ã‚µã‚¤ãƒˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆè³¼å…¥å®Œäº†ã®ã¿ï¼‰
ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ = å•†å“ã®æ³¨æ–‡ï¼ˆè³¼å…¥ï¼‰å®Œäº†
"""

import sys
import os
import json
import pandas as pd
from datetime import datetime, timedelta
from oauth_google_apis import OAuthGoogleAPIsIntegration

def analyze_7days_purchase_only():
    """ç›´è¿‘7æ—¥é–“ã®è©³ç´°åˆ†æã‚’å®Ÿè¡Œï¼ˆè³¼å…¥å®Œäº†ã®ã¿ï¼‰"""
    
    print("\n" + "=" * 70)
    print("  MOO-D MARK ã‚µã‚¤ãƒˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ - ç›´è¿‘7æ—¥é–“")
    print("  https://isetan.mistore.jp/moodmark")
    print("  ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ = å•†å“è³¼å…¥å®Œäº†ã®ã¿")
    print("=" * 70)
    
    # APIåˆæœŸåŒ–
    api = OAuthGoogleAPIsIntegration()
    
    if not api.credentials:
        print("\nâŒ èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...\n")
    
    # 1. æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ï¼ˆè³¼å…¥å®Œäº†ã®ã¿ï¼‰
    print("1ï¸âƒ£  æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æï¼ˆè³¼å…¥å®Œäº†ï¼‰")
    print("-" * 70)
    
    property_id = "316302380"
    
    daily_data = api.get_ga4_data(
        date_range_days=7,
        metrics=['sessions', 'activeUsers', 'screenPageViews', 'bounceRate', 
                'averageSessionDuration', 'ecommercePurchases', 'purchaseRevenue'],
        dimensions=['date', 'landingPage'],
        property_id=property_id
    )
    
    if not daily_data.empty:
        # moodmarkã§ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã—ãŸã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã¿ï¼ˆmoodmarkgiftã‚’é™¤å¤–ï¼‰
        moodmark_data = daily_data[
            (daily_data['landingPage'].str.contains('/moodmark', na=False)) & 
            (~daily_data['landingPage'].str.contains('/moodmarkgift/', na=False))
        ]
        
        if not moodmark_data.empty:
            daily_data = moodmark_data.groupby('date').agg({
                'sessions': 'sum',
                'activeUsers': 'sum',
                'screenPageViews': 'sum',
                'bounceRate': 'mean',
                'averageSessionDuration': 'mean',
                'ecommercePurchases': 'sum',
                'purchaseRevenue': 'sum'
            }).reset_index()
            
            daily_data = daily_data.sort_values('date')
            
            # è³¼å…¥å®Œäº†ç‡ï¼ˆCVRï¼‰ã‚’è¨ˆç®—
            daily_data['purchase_cvr'] = (daily_data['ecommercePurchases'] / daily_data['sessions'] * 100).round(2)
        else:
            print("âš ï¸ moodmarkã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            daily_data = pd.DataFrame()
    else:
        daily_data = pd.DataFrame()
    
    if not daily_data.empty:
        print(daily_data.to_string(index=False))
        
        # åˆè¨ˆå€¤
        print("\nğŸ“ˆ 7æ—¥é–“ã®åˆè¨ˆ:")
        print(f"   ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {daily_data['sessions'].sum():,.0f}")
        print(f"   ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {daily_data['activeUsers'].sum():,.0f}")
        print(f"   ç·ãƒšãƒ¼ã‚¸ãƒ“ãƒ¥ãƒ¼æ•°: {daily_data['screenPageViews'].sum():,.0f}")
        print(f"   **ç·è³¼å…¥æ•°ï¼ˆæ³¨æ–‡å®Œäº†ï¼‰: {daily_data['ecommercePurchases'].sum():,.0f}**")
        print(f"   **ç·è³¼å…¥é¡: Â¥{daily_data['purchaseRevenue'].sum():,.0f}**")
        
        # å¹³å‡å€¤
        print(f"\nğŸ“Š 7æ—¥é–“ã®å¹³å‡:")
        print(f"   å¹³å‡ç›´å¸°ç‡: {daily_data['bounceRate'].mean():.1%}")
        print(f"   å¹³å‡ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“: {daily_data['averageSessionDuration'].mean():.0f}ç§’")
        print(f"   **è³¼å…¥å®Œäº†ç‡ï¼ˆCVRï¼‰: {daily_data['purchase_cvr'].mean():.2f}%**")
        print(f"   **å¹³å‡æ³¨æ–‡å˜ä¾¡: Â¥{(daily_data['purchaseRevenue'].sum() / daily_data['ecommercePurchases'].sum()):,.0f}**")
    
    # 2. ãƒ‡ãƒã‚¤ã‚¹åˆ¥åˆ†æï¼ˆè³¼å…¥å®Œäº†ï¼‰
    print("\n\n2ï¸âƒ£  ãƒ‡ãƒã‚¤ã‚¹åˆ¥åˆ†æï¼ˆè³¼å…¥å®Œäº†ï¼‰")
    print("-" * 70)
    
    device_data = api.get_ga4_data(
        date_range_days=7,
        metrics=['sessions', 'activeUsers', 'bounceRate', 'ecommercePurchases', 'purchaseRevenue'],
        dimensions=['deviceCategory', 'landingPage'],
        property_id=property_id
    )
    
    if not device_data.empty:
        # moodmarkã§ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã—ãŸã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã¿
        moodmark_device_data = device_data[
            (device_data['landingPage'].str.contains('/moodmark', na=False)) & 
            (~device_data['landingPage'].str.contains('/moodmarkgift/', na=False))
        ]
        
        if not moodmark_device_data.empty:
            device_summary = moodmark_device_data.groupby('deviceCategory').agg({
                'sessions': 'sum',
                'activeUsers': 'sum',
                'bounceRate': 'mean',
                'ecommercePurchases': 'sum',
                'purchaseRevenue': 'sum'
            }).reset_index()
        
        device_summary['purchase_cvr'] = (device_summary['ecommercePurchases'] / device_summary['sessions'] * 100).round(2)
        device_summary['session_share'] = (device_summary['sessions'] / device_summary['sessions'].sum() * 100).round(1)
        device_summary['avg_order_value'] = (device_summary['purchaseRevenue'] / device_summary['ecommercePurchases']).round(0)
        
        print(device_summary.to_string(index=False))
        
        print("\nğŸ’¡ ãƒ‡ãƒã‚¤ã‚¹åˆ¥ã‚¤ãƒ³ã‚µã‚¤ãƒˆ:")
        for _, row in device_summary.iterrows():
            print(f"\n{row['deviceCategory']}:")
            print(f"  è³¼å…¥å®Œäº†æ•°: {row['ecommercePurchases']:,.0f}")
            print(f"  è³¼å…¥å®Œäº†ç‡: {row['purchase_cvr']:.2f}%")
            print(f"  å¹³å‡æ³¨æ–‡å˜ä¾¡: Â¥{row['avg_order_value']:,.0f}")
    
    # 3. ãƒãƒ£ãƒãƒ«åˆ¥åˆ†æï¼ˆè³¼å…¥å®Œäº†ï¼‰
    print("\n\n3ï¸âƒ£  ãƒãƒ£ãƒãƒ«åˆ¥åˆ†æï¼ˆè³¼å…¥å®Œäº†ï¼‰")
    print("-" * 70)
    
    channel_data = api.get_ga4_data(
        date_range_days=7,
        metrics=['sessions', 'activeUsers', 'ecommercePurchases', 'purchaseRevenue'],
        dimensions=['sessionDefaultChannelGrouping', 'landingPage'],
        property_id=property_id
    )
    
    if not channel_data.empty:
        # moodmarkã§ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã—ãŸã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã¿
        moodmark_channel_data = channel_data[
            (channel_data['landingPage'].str.contains('/moodmark', na=False)) & 
            (~channel_data['landingPage'].str.contains('/moodmarkgift/', na=False))
        ]
        
        if not moodmark_channel_data.empty:
            channel_summary = moodmark_channel_data.groupby('sessionDefaultChannelGrouping').agg({
                'sessions': 'sum',
                'activeUsers': 'sum',
                'ecommercePurchases': 'sum',
                'purchaseRevenue': 'sum'
            }).reset_index()
        
        channel_summary['purchase_cvr'] = (channel_summary['ecommercePurchases'] / channel_summary['sessions'] * 100).round(2)
        channel_summary['avg_order_value'] = (channel_summary['purchaseRevenue'] / channel_summary['ecommercePurchases']).round(0)
        channel_summary = channel_summary.sort_values('ecommercePurchases', ascending=False)
        
        print(channel_summary.to_string(index=False))
        
        print("\nğŸ’¡ ãƒãƒ£ãƒãƒ«åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:")
        for idx, row in channel_summary.head(5).iterrows():
            print(f"\n{row['sessionDefaultChannelGrouping']}:")
            print(f"  è³¼å…¥æ•°: {row['ecommercePurchases']:,.0f}")
            print(f"  è³¼å…¥å®Œäº†ç‡: {row['purchase_cvr']:.2f}%")
            print(f"  è³¼å…¥é¡: Â¥{row['purchaseRevenue']:,.0f}")
    
    # 4. äººæ°—ãƒšãƒ¼ã‚¸åˆ†æ
    print("\n\n4ï¸âƒ£  äººæ°—ãƒšãƒ¼ã‚¸ TOP10")
    print("-" * 70)
    
    page_data = api.get_ga4_data(
        date_range_days=7,
        metrics=['screenPageViews', 'sessions', 'bounceRate'],
        dimensions=['pagePath']
    )
    
    if not page_data.empty:
        page_summary = page_data.groupby('pagePath').agg({
            'screenPageViews': 'sum',
            'sessions': 'sum',
            'bounceRate': 'mean'
        }).reset_index()
        
        page_summary = page_summary.sort_values('screenPageViews', ascending=False).head(10)
        page_summary['bounceRate'] = page_summary['bounceRate'].apply(lambda x: f"{x:.1%}")
        
        print(page_summary.to_string(index=False))
    
    # 5. æ™‚é–“å¸¯åˆ¥ã‚¢ã‚¯ã‚»ã‚¹ãƒ»è³¼å…¥åˆ†æ
    print("\n\n5ï¸âƒ£  æ™‚é–“å¸¯åˆ¥ã‚¢ã‚¯ã‚»ã‚¹ãƒ»è³¼å…¥åˆ†æ")
    print("-" * 70)
    
    hourly_data = api.get_ga4_data(
        date_range_days=7,
        metrics=['sessions', 'totalUsers', 'ecommercePurchases'],
        dimensions=['dateHour']
    )
    
    if not hourly_data.empty:
        # æ™‚é–“ã‚’æŠ½å‡º
        hourly_data['hour'] = hourly_data['dateHour'].astype(str).str[-2:].astype(int)
        
        hourly_summary = hourly_data.groupby('hour').agg({
            'sessions': 'sum',
            'totalUsers': 'sum',
            'ecommercePurchases': 'sum'
        }).reset_index()
        
        hourly_summary['purchase_cvr'] = (hourly_summary['ecommercePurchases'] / hourly_summary['sessions'] * 100).round(2)
        hourly_summary = hourly_summary.sort_values('ecommercePurchases', ascending=False).head(10)
        
        print("è³¼å…¥ãŒå¤šã„æ™‚é–“å¸¯ TOP10:")
        print(hourly_summary.to_string(index=False))
    
    # 6. è³¼å…¥åˆ†æè©³ç´°
    print("\n\n6ï¸âƒ£  è³¼å…¥åˆ†æè©³ç´°")
    print("-" * 70)
    
    if not daily_data.empty:
        total_sessions = daily_data['sessions'].sum()
        total_purchases = daily_data['ecommercePurchases'].sum()
        total_revenue = daily_data['purchaseRevenue'].sum()
        purchase_cvr = (total_purchases / total_sessions * 100)
        avg_order_value = total_revenue / total_purchases if total_purchases > 0 else 0
        
        print(f"ğŸ“Š è³¼å…¥å®Œäº†ã®å…¨ä½“ã‚µãƒãƒªãƒ¼:")
        print(f"  ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {total_sessions:,.0f}")
        print(f"  ç·è³¼å…¥å®Œäº†æ•°: {total_purchases:,.0f}")
        print(f"  **è³¼å…¥å®Œäº†ç‡ï¼ˆCVRï¼‰: {purchase_cvr:.2f}%**")
        print(f"  ç·è³¼å…¥é¡: Â¥{total_revenue:,.0f}")
        print(f"  å¹³å‡æ³¨æ–‡å˜ä¾¡ï¼ˆAOVï¼‰: Â¥{avg_order_value:,.0f}")
        
        # ãƒ‡ãƒã‚¤ã‚¹åˆ¥è³¼å…¥å®Œäº†ç‡
        if not device_data.empty:
            print("\nğŸ“± ãƒ‡ãƒã‚¤ã‚¹åˆ¥è³¼å…¥å®Œäº†ç‡:")
            device_conv = device_data.groupby('deviceCategory').agg({
                'sessions': 'sum',
                'ecommercePurchases': 'sum'
            }).reset_index()
            device_conv['cvr'] = (device_conv['ecommercePurchases'] / device_conv['sessions'] * 100).round(2)
            print(device_conv[['deviceCategory', 'ecommercePurchases', 'cvr']].to_string(index=False))
        
        # ãƒãƒ£ãƒãƒ«åˆ¥è³¼å…¥å®Œäº†ç‡
        if not channel_data.empty:
            print("\nğŸ” ãƒãƒ£ãƒãƒ«åˆ¥è³¼å…¥å®Œäº†ç‡ TOP5:")
            channel_conv = channel_data.groupby('sessionDefaultChannelGrouping').agg({
                'sessions': 'sum',
                'ecommercePurchases': 'sum'
            }).reset_index()
            channel_conv['cvr'] = (channel_conv['ecommercePurchases'] / channel_conv['sessions'] * 100).round(2)
            channel_conv = channel_conv.sort_values('ecommercePurchases', ascending=False).head(5)
            print(channel_conv[['sessionDefaultChannelGrouping', 'ecommercePurchases', 'cvr']].to_string(index=False))
    
    # 7. åˆ†æã‚µãƒãƒªãƒ¼ã¨æ¨å¥¨äº‹é …
    print("\n\n7ï¸âƒ£  åˆ†æã‚µãƒãƒªãƒ¼ã¨æ¨å¥¨äº‹é …")
    print("-" * 70)
    
    recommendations = []
    
    if not daily_data.empty:
        avg_purchase_cvr = daily_data['purchase_cvr'].mean()
        avg_order_value = daily_data['purchaseRevenue'].sum() / daily_data['ecommercePurchases'].sum()
        
        print(f"\nâœ… è³¼å…¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:")
        print(f"   â€¢ è³¼å…¥å®Œäº†ç‡ï¼ˆCVRï¼‰: {avg_purchase_cvr:.2f}%")
        print(f"   â€¢ å¹³å‡æ³¨æ–‡å˜ä¾¡ï¼ˆAOVï¼‰: Â¥{avg_order_value:,.0f}")
        
        if avg_purchase_cvr > 5:
            recommendations.append("è³¼å…¥å®Œäº†ç‡ãŒ5%ä»¥ä¸Šã¨å„ªç§€ã§ã™ã€‚ç¾åœ¨ã®æ–½ç­–ã‚’ç¶™ç¶šã—ã¦ãã ã•ã„ã€‚")
        elif avg_purchase_cvr > 2:
            recommendations.append("è³¼å…¥å®Œäº†ç‡ã¯æ¨™æº–çš„ã§ã™ã€‚ã‚«ãƒ¼ãƒˆé›¢è„±ç‡ã®æ”¹å–„ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
        else:
            recommendations.append("è³¼å…¥å®Œäº†ç‡ãŒä½ã„ã§ã™ã€‚è³¼å…¥ãƒ•ãƒ­ãƒ¼å…¨ä½“ã®è¦‹ç›´ã—ãŒå¿…è¦ã§ã™ã€‚")
        
        if avg_order_value > 8000:
            recommendations.append("å¹³å‡æ³¨æ–‡å˜ä¾¡ãŒé«˜ã„ã§ã™ã€‚ã‚¢ãƒƒãƒ—ã‚»ãƒ«ãƒ»ã‚¯ãƒ­ã‚¹ã‚»ãƒ«æ–½ç­–ãŒåŠ¹æœçš„ã«æ©Ÿèƒ½ã—ã¦ã„ã¾ã™ã€‚")
        elif avg_order_value > 5000:
            recommendations.append("å¹³å‡æ³¨æ–‡å˜ä¾¡ã¯æ¨™æº–çš„ã§ã™ã€‚é–¢é€£å•†å“ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã®å¼·åŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
        else:
            recommendations.append("å¹³å‡æ³¨æ–‡å˜ä¾¡ãŒä½ã‚ã§ã™ã€‚ã‚»ãƒƒãƒˆå•†å“ã‚„ã¾ã¨ã‚è²·ã„ä¿ƒé€²æ–½ç­–ã‚’å¼·åŒ–ã—ã¦ãã ã•ã„ã€‚")
    
    if not device_data.empty:
        mobile_purchases = device_summary[device_summary['deviceCategory'] == 'mobile']['ecommercePurchases'].sum()
        desktop_purchases = device_summary[device_summary['deviceCategory'] == 'desktop']['ecommercePurchases'].sum()
        
        mobile_cvr = device_summary[device_summary['deviceCategory'] == 'mobile']['purchase_cvr'].values[0] if len(device_summary[device_summary['deviceCategory'] == 'mobile']) > 0 else 0
        desktop_cvr = device_summary[device_summary['deviceCategory'] == 'desktop']['purchase_cvr'].values[0] if len(device_summary[device_summary['deviceCategory'] == 'desktop']) > 0 else 0
        
        print(f"\nğŸ“± ãƒ‡ãƒã‚¤ã‚¹åˆ¥è³¼å…¥:")
        print(f"   â€¢ ãƒ¢ãƒã‚¤ãƒ«è³¼å…¥å®Œäº†ç‡: {mobile_cvr:.2f}%")
        print(f"   â€¢ ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—è³¼å…¥å®Œäº†ç‡: {desktop_cvr:.2f}%")
        
        if desktop_cvr > mobile_cvr * 1.5:
            recommendations.append("ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã®è³¼å…¥å®Œäº†ç‡ãŒé«˜ã„ã§ã™ã€‚ãƒ¢ãƒã‚¤ãƒ«ã®è³¼å…¥ãƒ•ãƒ­ãƒ¼æœ€é©åŒ–ã§å£²ä¸Šå¢—åŠ ãŒæœŸå¾…ã§ãã¾ã™ã€‚")
        
        if mobile_purchases > desktop_purchases * 5:
            recommendations.append("ãƒ¢ãƒã‚¤ãƒ«è³¼å…¥ãŒå¤§å¤šæ•°ã‚’å ã‚ã¦ã„ã¾ã™ã€‚ãƒ¢ãƒã‚¤ãƒ«æ±ºæ¸ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å……å®Ÿã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚")
    
    if recommendations:
        print(f"\nğŸ’¡ æ¨å¥¨äº‹é …:")
        for i, rec in enumerate(recommendations, 1):
            print(f"   {i}. {rec}")
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    print("\n\n8ï¸âƒ£  ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜")
    print("-" * 70)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # CSVä¿å­˜
    os.makedirs('data/processed', exist_ok=True)
    
    if not daily_data.empty:
        daily_data.to_csv(f'data/processed/daily_trend_purchase_7days_{timestamp}.csv', index=False, encoding='utf-8-sig')
        print(f"âœ… æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰: data/processed/daily_trend_purchase_7days_{timestamp}.csv")
    
    if not device_data.empty:
        device_summary.to_csv(f'data/processed/device_analysis_purchase_7days_{timestamp}.csv', index=False, encoding='utf-8-sig')
        print(f"âœ… ãƒ‡ãƒã‚¤ã‚¹åˆ¥åˆ†æ: data/processed/device_analysis_purchase_7days_{timestamp}.csv")
    
    if not channel_data.empty:
        channel_summary.to_csv(f'data/processed/channel_analysis_purchase_7days_{timestamp}.csv', index=False, encoding='utf-8-sig')
        print(f"âœ… ãƒãƒ£ãƒãƒ«åˆ¥åˆ†æ: data/processed/channel_analysis_purchase_7days_{timestamp}.csv")
    
    # JSONå½¢å¼ã§ã‚‚ä¿å­˜
    report = {
        'report_date': datetime.now().isoformat(),
        'period': 'ç›´è¿‘7æ—¥é–“',
        'conversion_definition': 'å•†å“ã®æ³¨æ–‡ï¼ˆè³¼å…¥ï¼‰å®Œäº†ã®ã¿',
        'site_url': 'https://isetan.mistore.jp/moodmark',
        'summary': {
            'total_sessions': int(daily_data['sessions'].sum()) if not daily_data.empty else 0,
            'total_users': int(daily_data['totalUsers'].sum()) if not daily_data.empty else 0,
            'total_pageviews': int(daily_data['screenPageViews'].sum()) if not daily_data.empty else 0,
            'total_purchases': int(daily_data['ecommercePurchases'].sum()) if not daily_data.empty else 0,
            'total_revenue': float(daily_data['purchaseRevenue'].sum()) if not daily_data.empty else 0,
            'avg_bounce_rate': float(daily_data['bounceRate'].mean()) if not daily_data.empty else 0,
            'avg_session_duration': float(daily_data['averageSessionDuration'].mean()) if not daily_data.empty else 0,
            'purchase_cvr': float((daily_data['ecommercePurchases'].sum() / daily_data['sessions'].sum() * 100)) if not daily_data.empty else 0,
            'avg_order_value': float(daily_data['purchaseRevenue'].sum() / daily_data['ecommercePurchases'].sum()) if not daily_data.empty and daily_data['ecommercePurchases'].sum() > 0 else 0
        },
        'recommendations': recommendations
    }
    
    report_file = f'data/processed/analysis_report_purchase_7days_{timestamp}.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
    
    print("\n" + "=" * 70)
    print("  åˆ†æå®Œäº†ï¼")
    print("=" * 70 + "\n")
    
    return report

if __name__ == "__main__":
    analyze_7days_purchase_only()

