#!/usr/bin/env python3
"""
æœŸé–“æŒ‡å®šåˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
- 2025/10/1-10/15æœŸé–“ã®åˆ†æ
- å‰å¹´åŒæœŸé–“å¯¾æ¯”
- 2ã‚µã‚¤ãƒˆåˆ¥ãƒ¬ãƒãƒ¼ãƒˆ
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import logging

# ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¾ãŸã¯çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦ã¿ã‚‹
try:
    from .oauth_google_apis import OAuthGoogleAPIsIntegration
except ImportError:
    from oauth_google_apis import OAuthGoogleAPIsIntegration

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/period_analysis.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class PeriodAnalysisReport:
    def __init__(self):
        """æœŸé–“åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
        # OAuthèªè¨¼ã‚’ä½¿ç”¨
        self.api_integration = OAuthGoogleAPIsIntegration()
        self.config = self._load_config()
        
        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        os.makedirs('logs', exist_ok=True)
        os.makedirs('data/processed', exist_ok=True)
    
    def _load_config(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        config_file = 'config/analytics_config.json'
        
        try:
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                return config
            else:
                logger.error("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {}
        except Exception as e:
            logger.error(f"è¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def get_period_data(self, start_date: str, end_date: str, site_config: Dict[str, str]):
        """
        æŒ‡å®šæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Args:
            start_date (str): é–‹å§‹æ—¥ (YYYY-MM-DD)
            end_date (str): çµ‚äº†æ—¥ (YYYY-MM-DD)
            site_config (dict): ã‚µã‚¤ãƒˆè¨­å®š
        
        Returns:
            dict: å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿
        """
        try:
            logger.info(f"æœŸé–“ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹: {start_date} - {end_date}")
            
            # ä¸€æ™‚çš„ã«ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£IDã¨ã‚µã‚¤ãƒˆURLã‚’è¨­å®š
            original_ga4_property_id = self.api_integration.ga4_property_id
            original_gsc_site_url = self.api_integration.gsc_site_url
            
            self.api_integration.ga4_property_id = site_config.get('ga4_property_id')
            self.api_integration.gsc_site_url = site_config.get('gsc_site_url')
            
            # æ—¥ä»˜ç¯„å›²ã®è¨ˆç®—
            start_dt = datetime.strptime(start_date, '%Y-%m-%d')
            end_dt = datetime.strptime(end_date, '%Y-%m-%d')
            date_range_days = (end_dt - start_dt).days + 1
            
            # GA4ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæœŸé–“æŒ‡å®šï¼‰
            ga4_data = self._get_ga4_data_for_period(start_date, end_date, site_config)
            
            # GSCãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæœŸé–“æŒ‡å®šï¼‰
            gsc_pages = self._get_gsc_pages_for_period(start_date, end_date, site_config)
            gsc_queries = self._get_gsc_queries_for_period(start_date, end_date, site_config)
            
            # å…ƒã®è¨­å®šã‚’å¾©å…ƒ
            self.api_integration.ga4_property_id = original_ga4_property_id
            self.api_integration.gsc_site_url = original_gsc_site_url
            
            return {
                'ga4_data': ga4_data,
                'gsc_pages': gsc_pages,
                'gsc_queries': gsc_queries,
                'period': f"{start_date} - {end_date}",
                'site_url': site_config.get('url', ''),
                'date_range_days': date_range_days
            }
            
        except Exception as e:
            logger.error(f"æœŸé–“ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _get_ga4_data_for_period(self, start_date: str, end_date: str, site_config: Dict[str, str]):
        """æœŸé–“æŒ‡å®šã§GA4ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            if not self.api_integration.ga4_service or not site_config.get('ga4_property_id'):
                logger.warning("GA4ã‚µãƒ¼ãƒ“ã‚¹ã¾ãŸã¯ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return pd.DataFrame()
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³
            metrics = [
                'sessions',
                'totalUsers', 
                'screenPageViews',
                'bounceRate',
                'averageSessionDuration',
                'conversions'
            ]
            
            dimensions = [
                'date',
                'pagePath',
                'sessionDefaultChannelGrouping',
                'deviceCategory'
            ]
            
            # GA4ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
            request_body = {
                'dateRanges': [{'startDate': start_date, 'endDate': end_date}],
                'metrics': [{'name': metric} for metric in metrics],
                'dimensions': [{'name': dimension} for dimension in dimensions],
                'limit': 10000
            }
            
            # APIå‘¼ã³å‡ºã—
            response = self.api_integration.ga4_service.properties().runReport(
                property=f"properties/{site_config['ga4_property_id']}",
                body=request_body
            ).execute()
            
            # ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
            data = []
            if 'rows' in response:
                for row in response['rows']:
                    row_data = {}
                    
                    # ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å€¤ã®å–å¾—
                    for i, dimension in enumerate(dimensions):
                        if i < len(row.get('dimensionValues', [])):
                            row_data[dimension] = row['dimensionValues'][i].get('value', '')
                    
                    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å€¤ã®å–å¾—
                    for i, metric in enumerate(metrics):
                        if i < len(row.get('metricValues', [])):
                            value = row['metricValues'][i].get('value', '0')
                            try:
                                row_data[metric] = float(value)
                            except ValueError:
                                row_data[metric] = value
                    
                    data.append(row_data)
            
            df = pd.DataFrame(data)
            logger.info(f"GA4ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(df)}è¡Œ")
            return df
            
        except Exception as e:
            logger.error(f"GA4ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    def _get_gsc_pages_for_period(self, start_date: str, end_date: str, site_config: Dict[str, str]):
        """æœŸé–“æŒ‡å®šã§GSCãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            if not self.api_integration.gsc_service or not site_config.get('gsc_site_url'):
                logger.warning("GSCã‚µãƒ¼ãƒ“ã‚¹ã¾ãŸã¯ã‚µã‚¤ãƒˆURLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return pd.DataFrame()
            
            # GSCãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
            request = {
                'startDate': start_date,
                'endDate': end_date,
                'dimensions': ['page'],
                'rowLimit': 10000,
                'startRow': 0
            }
            
            # APIå‘¼ã³å‡ºã—
            response = self.api_integration.gsc_service.searchanalytics().query(
                siteUrl=site_config['gsc_site_url'],
                body=request
            ).execute()
            
            # ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
            data = []
            if 'rows' in response:
                for row in response['rows']:
                    row_data = {
                        'page': row['keys'][0] if row.get('keys') else '',
                        'clicks': row.get('clicks', 0),
                        'impressions': row.get('impressions', 0),
                        'ctr': row.get('ctr', 0),
                        'position': row.get('position', 0)
                    }
                    data.append(row_data)
            
            df = pd.DataFrame(data)
            
            if not df.empty:
                # CTRã¨ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’è¨ˆç®—ã—ç›´ã—
                df['ctr_calculated'] = (df['clicks'] / df['impressions'] * 100).round(2)
                df['avg_position'] = df['position'].round(2)
                # ã‚½ãƒ¼ãƒˆï¼ˆã‚¯ãƒªãƒƒã‚¯æ•°é †ï¼‰
                df = df.sort_values('clicks', ascending=False).reset_index(drop=True)
            
            logger.info(f"GSCãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(df)}è¡Œ")
            return df
            
        except Exception as e:
            logger.error(f"GSCãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    def _get_gsc_queries_for_period(self, start_date: str, end_date: str, site_config: Dict[str, str]):
        """æœŸé–“æŒ‡å®šã§GSCã‚¯ã‚¨ãƒªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            if not self.api_integration.gsc_service or not site_config.get('gsc_site_url'):
                logger.warning("GSCã‚µãƒ¼ãƒ“ã‚¹ã¾ãŸã¯ã‚µã‚¤ãƒˆURLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return pd.DataFrame()
            
            # GSCãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
            request = {
                'startDate': start_date,
                'endDate': end_date,
                'dimensions': ['query'],
                'rowLimit': 10000,
                'startRow': 0
            }
            
            # APIå‘¼ã³å‡ºã—
            response = self.api_integration.gsc_service.searchanalytics().query(
                siteUrl=site_config['gsc_site_url'],
                body=request
            ).execute()
            
            # ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
            data = []
            if 'rows' in response:
                for row in response['rows']:
                    row_data = {
                        'query': row['keys'][0] if row.get('keys') else '',
                        'clicks': row.get('clicks', 0),
                        'impressions': row.get('impressions', 0),
                        'ctr': row.get('ctr', 0),
                        'position': row.get('position', 0)
                    }
                    data.append(row_data)
            
            df = pd.DataFrame(data)
            
            if not df.empty:
                # CTRã¨ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’è¨ˆç®—ã—ç›´ã—
                df['ctr_calculated'] = (df['clicks'] / df['impressions'] * 100).round(2)
                df['avg_position'] = df['position'].round(2)
                # ã‚½ãƒ¼ãƒˆï¼ˆã‚¯ãƒªãƒƒã‚¯æ•°é †ï¼‰
                df = df.sort_values('clicks', ascending=False).reset_index(drop=True)
            
            logger.info(f"GSCã‚¯ã‚¨ãƒªãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(df)}è¡Œ")
            return df
            
        except Exception as e:
            logger.error(f"GSCã‚¯ã‚¨ãƒªãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    def generate_site_report(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚µã‚¤ãƒˆåˆ¥ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        try:
            logger.info(f"ã‚µã‚¤ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹: {data['site_url']}")
            
            report = {
                'site_url': data['site_url'],
                'period': data['period'],
                'date_range_days': data['date_range_days'],
                'generated_at': datetime.now().isoformat(),
                'ga4_summary': {},
                'gsc_summary': {},
                'top_pages': [],
                'top_queries': [],
                'recommendations': []
            }
            
            # GA4ã‚µãƒãƒªãƒ¼
            if not data['ga4_data'].empty:
                ga4_data = data['ga4_data']
                report['ga4_summary'] = {
                    'total_sessions': int(ga4_data['sessions'].sum()) if 'sessions' in ga4_data.columns else 0,
                    'total_users': int(ga4_data['totalUsers'].sum()) if 'totalUsers' in ga4_data.columns else 0,
                    'total_pageviews': int(ga4_data['screenPageViews'].sum()) if 'screenPageViews' in ga4_data.columns else 0,
                    'avg_bounce_rate': float(ga4_data['bounceRate'].mean()) if 'bounceRate' in ga4_data.columns else 0,
                    'avg_session_duration': float(ga4_data['averageSessionDuration'].mean()) if 'averageSessionDuration' in ga4_data.columns else 0,
                    'total_conversions': int(ga4_data['conversions'].sum()) if 'conversions' in ga4_data.columns else 0,
                    'data_rows': len(ga4_data)
                }
            else:
                report['ga4_summary'] = {
                    'total_sessions': 0,
                    'total_users': 0,
                    'total_pageviews': 0,
                    'avg_bounce_rate': 0,
                    'avg_session_duration': 0,
                    'total_conversions': 0,
                    'data_rows': 0
                }
            
            # GSCã‚µãƒãƒªãƒ¼ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
            if not data['gsc_pages'].empty:
                gsc_pages = data['gsc_pages']
                report['gsc_summary'] = {
                    'total_clicks': gsc_pages['clicks'].sum(),
                    'total_impressions': gsc_pages['impressions'].sum(),
                    'avg_ctr': gsc_pages['ctr_calculated'].mean() if 'ctr_calculated' in gsc_pages.columns else 0,
                    'avg_position': gsc_pages['avg_position'].mean() if 'avg_position' in gsc_pages.columns else 0,
                    'top_pages_count': len(gsc_pages)
                }
                
                # ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ï¼ˆä¸Šä½10ä»¶ï¼‰
                report['top_pages'] = gsc_pages.head(10).to_dict('records')
            else:
                report['gsc_summary'] = {
                    'total_clicks': 0,
                    'total_impressions': 0,
                    'avg_ctr': 0,
                    'avg_position': 0,
                    'top_pages_count': 0
                }
                report['top_pages'] = []
            
            # ãƒˆãƒƒãƒ—ã‚¯ã‚¨ãƒªï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
            if not data['gsc_queries'].empty:
                gsc_queries = data['gsc_queries']
                report['gsc_summary']['top_queries_count'] = len(gsc_queries)
                report['top_queries'] = gsc_queries.head(20).to_dict('records')
            else:
                report['gsc_summary']['top_queries_count'] = 0
                report['top_queries'] = []
            
            # æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
            self._generate_recommendations(report)
            
            logger.info(f"ã‚µã‚¤ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {data['site_url']}")
            return report
            
        except Exception as e:
            logger.error(f"ã‚µã‚¤ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _generate_recommendations(self, report: Dict[str, Any]):
        """æ¨å¥¨äº‹é …ã®ç”Ÿæˆ"""
        recommendations = []
        
        # GA4é–¢é€£ã®æ¨å¥¨äº‹é …
        ga4_summary = report.get('ga4_summary', {})
        if ga4_summary.get('avg_bounce_rate', 0) > 0.6:
            recommendations.append({
                'type': 'performance',
                'priority': 'high',
                'message': f"ãƒã‚¦ãƒ³ã‚¹ç‡ãŒ{ga4_summary['avg_bounce_rate']:.1%}ã¨é«˜ã™ãã¾ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ”¹å–„ãŒå¿…è¦ã§ã™ã€‚"
            })
        
        if ga4_summary.get('avg_session_duration', 0) < 60:
            recommendations.append({
                'type': 'engagement',
                'priority': 'medium',
                'message': f"å¹³å‡ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“ãŒ{ga4_summary['avg_session_duration']:.0f}ç§’ã¨çŸ­ã™ãã¾ã™ã€‚ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå‘ä¸ŠãŒå¿…è¦ã§ã™ã€‚"
            })
        
        # GSCé–¢é€£ã®æ¨å¥¨äº‹é …
        gsc_summary = report.get('gsc_summary', {})
        if gsc_summary.get('avg_position', 0) > 10:
            recommendations.append({
                'type': 'seo',
                'priority': 'high',
                'message': f"å¹³å‡æ¤œç´¢é †ä½ãŒ{gsc_summary['avg_position']:.1f}ä½ã¨ä½ã™ãã¾ã™ã€‚SEOæ”¹å–„ãŒå¿…è¦ã§ã™ã€‚"
            })
        
        if gsc_summary.get('avg_ctr', 0) < 2:
            recommendations.append({
                'type': 'seo',
                'priority': 'medium',
                'message': f"CTRãŒ{gsc_summary['avg_ctr']:.2f}%ã¨ä½ã™ãã¾ã™ã€‚ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒ¡ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã®æœ€é©åŒ–ãŒå¿…è¦ã§ã™ã€‚"
            })
        
        report['recommendations'] = recommendations
    
    def compare_periods(self, current_data: Dict[str, Any], previous_data: Dict[str, Any]) -> Dict[str, Any]:
        """æœŸé–“æ¯”è¼ƒåˆ†æ"""
        try:
            logger.info("æœŸé–“æ¯”è¼ƒåˆ†æé–‹å§‹")
            
            comparison = {
                'current_period': current_data['period'],
                'previous_period': previous_data['period'],
                'ga4_comparison': {},
                'gsc_comparison': {},
                'growth_analysis': {}
            }
            
            # GA4æ¯”è¼ƒ
            current_ga4 = current_data.get('ga4_summary', {})
            previous_ga4 = previous_data.get('ga4_summary', {})
            
            for metric in ['total_sessions', 'total_users', 'total_pageviews', 'total_conversions', 'total_revenue']:
                current_val = current_ga4.get(metric, 0)
                previous_val = previous_ga4.get(metric, 0)
                
                if previous_val > 0:
                    growth_rate = ((current_val - previous_val) / previous_val) * 100
                    comparison['ga4_comparison'][metric] = {
                        'current': current_val,
                        'previous': previous_val,
                        'growth_rate': growth_rate,
                        'growth_direction': 'increase' if growth_rate > 0 else 'decrease'
                    }
            
            # GSCæ¯”è¼ƒ
            current_gsc = current_data.get('gsc_summary', {})
            previous_gsc = previous_data.get('gsc_summary', {})
            
            for metric in ['total_clicks', 'total_impressions']:
                current_val = current_gsc.get(metric, 0)
                previous_val = previous_gsc.get(metric, 0)
                
                if previous_val > 0:
                    growth_rate = ((current_val - previous_val) / previous_val) * 100
                    comparison['gsc_comparison'][metric] = {
                        'current': current_val,
                        'previous': previous_val,
                        'growth_rate': growth_rate,
                        'growth_direction': 'increase' if growth_rate > 0 else 'decrease'
                    }
            
            # æˆé•·åˆ†æ
            comparison['growth_analysis'] = self._analyze_growth_trends(comparison)
            
            logger.info("æœŸé–“æ¯”è¼ƒåˆ†æå®Œäº†")
            return comparison
            
        except Exception as e:
            logger.error(f"æœŸé–“æ¯”è¼ƒåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _analyze_growth_trends(self, comparison: Dict[str, Any]) -> Dict[str, Any]:
        """æˆé•·ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        growth_analysis = {
            'overall_trend': 'stable',
            'key_insights': [],
            'concerns': []
        }
        
        # GA4æˆé•·ç‡ã®åˆ†æ
        ga4_growth_rates = []
        for metric, data in comparison.get('ga4_comparison', {}).items():
            growth_rate = data.get('growth_rate', 0)
            ga4_growth_rates.append(growth_rate)
            
            if growth_rate > 20:
                growth_analysis['key_insights'].append(f"{metric}ãŒ{growth_rate:.1f}%å¤§å¹…å¢—åŠ ")
            elif growth_rate < -20:
                growth_analysis['concerns'].append(f"{metric}ãŒ{abs(growth_rate):.1f}%å¤§å¹…æ¸›å°‘")
        
        # GSCæˆé•·ç‡ã®åˆ†æ
        gsc_growth_rates = []
        for metric, data in comparison.get('gsc_comparison', {}).items():
            growth_rate = data.get('growth_rate', 0)
            gsc_growth_rates.append(growth_rate)
            
            if growth_rate > 20:
                growth_analysis['key_insights'].append(f"{metric}ãŒ{growth_rate:.1f}%å¤§å¹…å¢—åŠ ")
            elif growth_rate < -20:
                growth_analysis['concerns'].append(f"{metric}ãŒ{abs(growth_rate):.1f}%å¤§å¹…æ¸›å°‘")
        
        # å…¨ä½“ãƒˆãƒ¬ãƒ³ãƒ‰ã®åˆ¤å®š
        all_growth_rates = ga4_growth_rates + gsc_growth_rates
        if all_growth_rates:
            avg_growth = sum(all_growth_rates) / len(all_growth_rates)
            if avg_growth > 10:
                growth_analysis['overall_trend'] = 'positive'
            elif avg_growth < -10:
                growth_analysis['overall_trend'] = 'negative'
        
        return growth_analysis
    
    def generate_comprehensive_report(self, start_date: str, end_date: str, previous_start_date: str, previous_end_date: str):
        """åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        try:
            logger.info("åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹")
            
            # ã‚µã‚¤ãƒˆè¨­å®šã®å–å¾—
            sites_config = self.config.get('sites', {})
            
            comprehensive_report = {
                'report_metadata': {
                    'generated_at': datetime.now().isoformat(),
                    'current_period': f"{start_date} - {end_date}",
                    'previous_period': f"{previous_start_date} - {previous_end_date}",
                    'sites_analyzed': list(sites_config.keys())
                },
                'sites': {},
                'comparison_analysis': {}
            }
            
            # å„ã‚µã‚¤ãƒˆã®åˆ†æ
            for site_name, site_config in sites_config.items():
                logger.info(f"ã‚µã‚¤ãƒˆåˆ†æé–‹å§‹: {site_name}")
                
                # ç¾åœ¨æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
                current_data = self.get_period_data(start_date, end_date, site_config)
                if not current_data:
                    logger.error(f"ç¾åœ¨æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—: {site_name}")
                    continue
                
                # å‰å¹´åŒæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
                previous_data = self.get_period_data(previous_start_date, previous_end_date, site_config)
                if not previous_data:
                    logger.warning(f"å‰å¹´åŒæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—: {site_name}")
                    previous_data = {}
                
                # ã‚µã‚¤ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                site_report = self.generate_site_report(current_data)
                
                # æœŸé–“æ¯”è¼ƒï¼ˆå‰å¹´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
                if previous_data:
                    comparison = self.compare_periods(current_data, previous_data)
                    site_report['year_over_year_comparison'] = comparison
                
                comprehensive_report['sites'][site_name] = site_report
                
                # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                self._save_site_data(current_data, site_name, start_date, end_date)
                if previous_data:
                    self._save_site_data(previous_data, site_name, previous_start_date, previous_end_date)
            
            # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
            report_file = f'data/processed/comprehensive_report_{start_date.replace("-", "")}_{end_date.replace("-", "")}.json'
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(comprehensive_report, f, ensure_ascii=False, indent=2)
            
            # Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            markdown_report = self._generate_markdown_report(comprehensive_report)
            markdown_file = f'data/processed/comprehensive_report_{start_date.replace("-", "")}_{end_date.replace("-", "")}.md'
            with open(markdown_file, 'w', encoding='utf-8') as f:
                f.write(markdown_report)
            
            logger.info(f"åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_file}")
            return comprehensive_report
            
        except Exception as e:
            logger.error(f"åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _save_site_data(self, data: Dict[str, Any], site_name: str, start_date: str, end_date: str):
        """ã‚µã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜"""
        try:
            timestamp = f"{start_date.replace('-', '')}_{end_date.replace('-', '')}"
            
            # GA4ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            if not data['ga4_data'].empty:
                filename = f'ga4_{site_name}_{timestamp}.csv'
                self.api_integration.export_to_csv(data['ga4_data'], filename)
            
            # GSCãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            if not data['gsc_pages'].empty:
                filename = f'gsc_pages_{site_name}_{timestamp}.csv'
                self.api_integration.export_to_csv(data['gsc_pages'], filename)
            
            # GSCã‚¯ã‚¨ãƒªãƒ‡ãƒ¼ã‚¿ä¿å­˜
            if not data['gsc_queries'].empty:
                filename = f'gsc_queries_{site_name}_{timestamp}.csv'
                self.api_integration.export_to_csv(data['gsc_queries'], filename)
                
        except Exception as e:
            logger.error(f"ã‚µã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _generate_markdown_report(self, report: Dict[str, Any]) -> str:
        """Markdownãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        try:
            metadata = report['report_metadata']
            
            markdown = f"""# ğŸ“Š MOO-D MARK æœŸé–“åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}
**åˆ†ææœŸé–“**: {metadata['current_period']}
**å‰å¹´åŒæœŸé–“**: {metadata['previous_period']}

## ğŸ“ˆ åˆ†ææ¦‚è¦

ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ã€MOO-D MARKã®2ã¤ã®ã‚µã‚¤ãƒˆã«ã¤ã„ã¦ã€æŒ‡å®šæœŸé–“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åˆ†æã—ãŸã‚‚ã®ã§ã™ã€‚

### åˆ†æå¯¾è±¡ã‚µã‚¤ãƒˆ
"""
            
            for site_name, site_data in report['sites'].items():
                site_url = site_data.get('site_url', '')
                markdown += f"- **{site_name}**: {site_url}\n"
            
            markdown += "\n## ğŸ“Š ã‚µã‚¤ãƒˆåˆ¥åˆ†æçµæœ\n\n"
            
            # å„ã‚µã‚¤ãƒˆã®è©³ç´°åˆ†æ
            for site_name, site_data in report['sites'].items():
                markdown += f"### ğŸŒ {site_name.upper()}\n\n"
                markdown += f"**ã‚µã‚¤ãƒˆURL**: {site_data.get('site_url', '')}\n\n"
                
                # GA4ã‚µãƒãƒªãƒ¼
                ga4_summary = site_data.get('ga4_summary', {})
                if ga4_summary:
                    markdown += "#### ğŸ“ˆ GA4 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹\n\n"
                    markdown += f"- **ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°**: {ga4_summary.get('total_sessions', 0):,}\n"
                    markdown += f"- **ç·ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°**: {ga4_summary.get('total_users', 0):,}\n"
                    markdown += f"- **ç·ãƒšãƒ¼ã‚¸ãƒ“ãƒ¥ãƒ¼æ•°**: {ga4_summary.get('total_pageviews', 0):,}\n"
                    markdown += f"- **å¹³å‡ãƒã‚¦ãƒ³ã‚¹ç‡**: {ga4_summary.get('avg_bounce_rate', 0):.1%}\n"
                    markdown += f"- **å¹³å‡ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“**: {ga4_summary.get('avg_session_duration', 0):.0f}ç§’\n"
                    markdown += f"- **ç·ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°**: {ga4_summary.get('total_conversions', 0):,}\n"
                    markdown += f"- **ç·åç›Š**: Â¥{ga4_summary.get('total_revenue', 0):,.0f}\n\n"
                
                # GSCã‚µãƒãƒªãƒ¼
                gsc_summary = site_data.get('gsc_summary', {})
                if gsc_summary:
                    markdown += "#### ğŸ” æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³æœ€é©åŒ– (SEO)\n\n"
                    markdown += f"- **ç·ã‚¯ãƒªãƒƒã‚¯æ•°**: {gsc_summary.get('total_clicks', 0):,}\n"
                    markdown += f"- **ç·ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°**: {gsc_summary.get('total_impressions', 0):,}\n"
                    markdown += f"- **å¹³å‡CTR**: {gsc_summary.get('avg_ctr', 0):.2f}%\n"
                    markdown += f"- **å¹³å‡æ¤œç´¢é †ä½**: {gsc_summary.get('avg_position', 0):.1f}ä½\n\n"
                
                # å‰å¹´åŒæœŸé–“å¯¾æ¯”
                yoy_comparison = site_data.get('year_over_year_comparison', {})
                if yoy_comparison:
                    markdown += "#### ğŸ“Š å‰å¹´åŒæœŸé–“å¯¾æ¯”\n\n"
                    
                    # GA4æ¯”è¼ƒ
                    ga4_comparison = yoy_comparison.get('ga4_comparison', {})
                    if ga4_comparison:
                        markdown += "**GA4æŒ‡æ¨™ã®å¤‰åŒ–**:\n"
                        for metric, data in ga4_comparison.items():
                            growth_rate = data.get('growth_rate', 0)
                            direction = "ğŸ“ˆ" if growth_rate > 0 else "ğŸ“‰" if growth_rate < 0 else "â¡ï¸"
                            markdown += f"- {metric}: {direction} {growth_rate:+.1f}%\n"
                        markdown += "\n"
                    
                    # GSCæ¯”è¼ƒ
                    gsc_comparison = yoy_comparison.get('gsc_comparison', {})
                    if gsc_comparison:
                        markdown += "**GSCæŒ‡æ¨™ã®å¤‰åŒ–**:\n"
                        for metric, data in gsc_comparison.items():
                            growth_rate = data.get('growth_rate', 0)
                            direction = "ğŸ“ˆ" if growth_rate > 0 else "ğŸ“‰" if growth_rate < 0 else "â¡ï¸"
                            markdown += f"- {metric}: {direction} {growth_rate:+.1f}%\n"
                        markdown += "\n"
                    
                    # æˆé•·åˆ†æ
                    growth_analysis = yoy_comparison.get('growth_analysis', {})
                    if growth_analysis:
                        trend = growth_analysis.get('overall_trend', 'stable')
                        trend_emoji = "ğŸ“ˆ" if trend == 'positive' else "ğŸ“‰" if trend == 'negative' else "â¡ï¸"
                        markdown += f"**å…¨ä½“ãƒˆãƒ¬ãƒ³ãƒ‰**: {trend_emoji} {trend}\n\n"
                        
                        if growth_analysis.get('key_insights'):
                            markdown += "**ä¸»è¦ã‚¤ãƒ³ã‚µã‚¤ãƒˆ**:\n"
                            for insight in growth_analysis['key_insights']:
                                markdown += f"- âœ… {insight}\n"
                            markdown += "\n"
                        
                        if growth_analysis.get('concerns'):
                            markdown += "**æ‡¸å¿µäº‹é …**:\n"
                            for concern in growth_analysis['concerns']:
                                markdown += f"- âš ï¸ {concern}\n"
                            markdown += "\n"
                
                # æ¨å¥¨äº‹é …
                recommendations = site_data.get('recommendations', [])
                if recommendations:
                    markdown += "#### ğŸ’¡ æ¨å¥¨äº‹é …\n\n"
                    for rec in recommendations:
                        priority_emoji = "ğŸ”´" if rec.get('priority') == 'high' else "ğŸŸ¡" if rec.get('priority') == 'medium' else "ğŸŸ¢"
                        markdown += f"- {priority_emoji} **{rec.get('type', '').upper()}**: {rec.get('message', '')}\n"
                    markdown += "\n"
                
                # ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸
                top_pages = site_data.get('top_pages', [])
                if top_pages:
                    markdown += "#### ğŸ† ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ (ä¸Šä½10ä»¶)\n\n"
                    markdown += "| é †ä½ | ãƒšãƒ¼ã‚¸ | ã‚¯ãƒªãƒƒã‚¯æ•° | ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•° | CTR | å¹³å‡é †ä½ |\n"
                    markdown += "|------|--------|------------|-------------------|-----|----------|\n"
                    for i, page in enumerate(top_pages[:10], 1):
                        markdown += f"| {i} | {page.get('page', '')[:50]}... | {page.get('clicks', 0):,} | {page.get('impressions', 0):,} | {page.get('ctr_calculated', 0):.2f}% | {page.get('avg_position', 0):.1f} |\n"
                    markdown += "\n"
                
                # ãƒˆãƒƒãƒ—ã‚¯ã‚¨ãƒª
                top_queries = site_data.get('top_queries', [])
                if top_queries:
                    markdown += "#### ğŸ” ãƒˆãƒƒãƒ—ã‚¯ã‚¨ãƒª (ä¸Šä½20ä»¶)\n\n"
                    markdown += "| é †ä½ | ã‚¯ã‚¨ãƒª | ã‚¯ãƒªãƒƒã‚¯æ•° | ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•° | CTR | å¹³å‡é †ä½ |\n"
                    markdown += "|------|--------|------------|-------------------|-----|----------|\n"
                    for i, query in enumerate(top_queries[:20], 1):
                        markdown += f"| {i} | {query.get('query', '')} | {query.get('clicks', 0):,} | {query.get('impressions', 0):,} | {query.get('ctr_calculated', 0):.2f}% | {query.get('avg_position', 0):.1f} |\n"
                    markdown += "\n"
                
                markdown += "---\n\n"
            
            markdown += """## ğŸ“‹ ã¾ã¨ã‚

ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ã€MOO-D MARKã®2ã¤ã®ã‚µã‚¤ãƒˆã«ã¤ã„ã¦ã€æŒ‡å®šæœŸé–“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©³ç´°ã«åˆ†æã—ãŸã‚‚ã®ã§ã™ã€‚

### ä¸»è¦ãªç™ºè¦‹
- å„ã‚µã‚¤ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚’è©³ç´°ã«åˆ†æ
- å‰å¹´åŒæœŸé–“ã¨ã®æ¯”è¼ƒã«ã‚ˆã‚Šæˆé•·ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æŠŠæ¡
- SEOã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã®æ”¹å–„ç‚¹ã‚’ç‰¹å®š

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
1. æ¨å¥¨äº‹é …ã®å„ªå…ˆé †ä½ä»˜ã‘ã¨å®Ÿè£…è¨ˆç”»ã®ç­–å®š
2. ç¶™ç¶šçš„ãªãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨æ”¹å–„ã®å®Ÿæ–½
3. å®šæœŸçš„ãªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«ã‚ˆã‚‹é€²æ—ç®¡ç†

---
*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚è©³ç´°ãªãƒ‡ãƒ¼ã‚¿ã¯æ·»ä»˜ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã”ç¢ºèªãã ã•ã„ã€‚*
"""
            
            return markdown
            
        except Exception as e:
            logger.error(f"Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return "ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=== æœŸé–“åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  ===")
    
    # åˆ†ææœŸé–“ã®è¨­å®š
    current_start_date = "2025-10-01"
    current_end_date = "2025-10-15"
    previous_start_date = "2024-10-01"
    previous_end_date = "2024-10-15"
    
    print(f"åˆ†ææœŸé–“: {current_start_date} - {current_end_date}")
    print(f"å‰å¹´åŒæœŸé–“: {previous_start_date} - {previous_end_date}")
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    analyzer = PeriodAnalysisReport()
    
    # åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = analyzer.generate_comprehensive_report(
        current_start_date, current_end_date,
        previous_start_date, previous_end_date
    )
    
    if report:
        print("\n=== åˆ†æå®Œäº† ===")
        print(f"ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: data/processed/comprehensive_report_{current_start_date.replace('-', '')}_{current_end_date.replace('-', '')}.json")
        print(f"Markdownãƒ¬ãƒãƒ¼ãƒˆ: data/processed/comprehensive_report_{current_start_date.replace('-', '')}_{current_end_date.replace('-', '')}.md")
        
        # ç°¡å˜ãªã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print("\n=== åˆ†æã‚µãƒãƒªãƒ¼ ===")
        for site_name, site_data in report['sites'].items():
            print(f"\nğŸŒ {site_name.upper()}")
            ga4_summary = site_data.get('ga4_summary', {})
            gsc_summary = site_data.get('gsc_summary', {})
            
            if ga4_summary:
                print(f"  ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {ga4_summary.get('total_sessions', 0):,}")
                print(f"  ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {ga4_summary.get('total_users', 0):,}")
                print(f"  ãƒšãƒ¼ã‚¸ãƒ“ãƒ¥ãƒ¼æ•°: {ga4_summary.get('total_pageviews', 0):,}")
            
            if gsc_summary:
                print(f"  ã‚¯ãƒªãƒƒã‚¯æ•°: {gsc_summary.get('total_clicks', 0):,}")
                print(f"  ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°: {gsc_summary.get('total_impressions', 0):,}")
                print(f"  å¹³å‡CTR: {gsc_summary.get('avg_ctr', 0):.2f}%")
    else:
        print("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()
