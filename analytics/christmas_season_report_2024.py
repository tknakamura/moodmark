#!/usr/bin/env python3
"""
2024å¹´ã‚¯ãƒªã‚¹ãƒã‚¹ã‚·ãƒ¼ã‚ºãƒ³ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
- 2024å¹´11-12æœˆã®ã‚¯ãƒªã‚¹ãƒã‚¹é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
- GA4ãƒ»GSC APIé€£æºã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿å–å¾—
- ã‚¯ãƒªã‚¹ãƒã‚¹æœŸé–“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import logging

# ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¾ãŸã¯çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦ã¿ã‚‹
try:
    from .google_apis_integration import GoogleAPIsIntegration
except ImportError:
    from google_apis_integration import GoogleAPIsIntegration

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/christmas_season_report.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ChristmasSeasonReportGenerator:
    def __init__(self, credentials_file=None):
        """
        ã‚¯ãƒªã‚¹ãƒã‚¹ã‚·ãƒ¼ã‚ºãƒ³ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–
        
        Args:
            credentials_file (str): ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        self.api_integration = GoogleAPIsIntegration(credentials_file)
        self.christmas_keywords = self._define_christmas_keywords()
        self.report_period = {
            'start_date': '2024-11-01',
            'end_date': '2024-12-31'
        }
        
        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        os.makedirs('logs', exist_ok=True)
        os.makedirs('data/processed', exist_ok=True)
        os.makedirs('data/christmas_2024', exist_ok=True)
    
    def _define_christmas_keywords(self) -> Dict[str, List[str]]:
        """ã‚¯ãƒªã‚¹ãƒã‚¹é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å®šç¾©"""
        return {
            'christmas_core': [
                'ã‚¯ãƒªã‚¹ãƒã‚¹', 'christmas', 'Xmas', 'ã‚¯ãƒªã‚¹ãƒã‚¹ãƒ—ãƒ¬ã‚¼ãƒ³ãƒˆ',
                'ã‚¯ãƒªã‚¹ãƒã‚¹ã‚®ãƒ•ãƒˆ', 'ã‚¯ãƒªã‚¹ãƒã‚¹ ãƒ—ãƒ¬ã‚¼ãƒ³ãƒˆ', 'ã‚¯ãƒªã‚¹ãƒã‚¹ ã‚®ãƒ•ãƒˆ'
            ],
            'gift_related': [
                'ãƒ—ãƒ¬ã‚¼ãƒ³ãƒˆ', 'ã‚®ãƒ•ãƒˆ', 'è´ˆã‚Šç‰©', 'ãƒ—ãƒ¬ã‚¼ãƒ³ãƒˆ ã‚¯ãƒªã‚¹ãƒã‚¹',
                'ã‚®ãƒ•ãƒˆ ã‚¯ãƒªã‚¹ãƒã‚¹', 'ã‚¯ãƒªã‚¹ãƒã‚¹ ãŠè“å­', 'ã‚¯ãƒªã‚¹ãƒã‚¹ ã‚¹ã‚¤ãƒ¼ãƒ„'
            ],
            'occasion_related': [
                'ã‚¯ãƒªã‚¹ãƒã‚¹ èª•ç”Ÿæ—¥', 'ã‚¯ãƒªã‚¹ãƒã‚¹ ã‚¤ãƒ–', 'ã‚µãƒ³ã‚¿ã‚¯ãƒ­ãƒ¼ã‚¹',
                'ã‚¯ãƒªã‚¹ãƒã‚¹ ã‚±ãƒ¼ã‚­', 'ã‚¯ãƒªã‚¹ãƒã‚¹ ãƒ‡ã‚£ãƒŠãƒ¼', 'ã‚¯ãƒªã‚¹ãƒã‚¹ ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼'
            ],
            'recipient_related': [
                'ã‚¯ãƒªã‚¹ãƒã‚¹ å½¼æ°', 'ã‚¯ãƒªã‚¹ãƒã‚¹ å½¼å¥³', 'ã‚¯ãƒªã‚¹ãƒã‚¹ å®¶æ—',
                'ã‚¯ãƒªã‚¹ãƒã‚¹ å‹é”', 'ã‚¯ãƒªã‚¹ãƒã‚¹ å­ä¾›', 'ã‚¯ãƒªã‚¹ãƒã‚¹ æ‹äºº'
            ],
            'product_related': [
                'ã‚¯ãƒªã‚¹ãƒã‚¹ ã‚³ã‚¹ãƒ¡', 'ã‚¯ãƒªã‚¹ãƒã‚¹ èŠ±æŸ', 'ã‚¯ãƒªã‚¹ãƒã‚¹ ãŠé…’',
                'ã‚¯ãƒªã‚¹ãƒã‚¹ ã‚¢ã‚¯ã‚»ã‚µãƒªãƒ¼', 'ã‚¯ãƒªã‚¹ãƒã‚¹ é›‘è²¨', 'ã‚¯ãƒªã‚¹ãƒã‚¹ é£Ÿå“'
            ]
        }
    
    def get_christmas_gsc_data(self) -> Dict[str, pd.DataFrame]:
        """
        ã‚¯ãƒªã‚¹ãƒã‚¹é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®GSCãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Returns:
            Dict[str, pd.DataFrame]: ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®GSCãƒ‡ãƒ¼ã‚¿
        """
        logger.info("ã‚¯ãƒªã‚¹ãƒã‚¹é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®GSCãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹")
        
        christmas_data = {}
        
        try:
            # å…¨æœŸé–“ã®GSCãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            gsc_data = self._get_custom_gsc_data(
                start_date=self.report_period['start_date'],
                end_date=self.report_period['end_date']
            )
            
            if gsc_data.empty:
                logger.warning("GSCãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return christmas_data
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            for category, keywords in self.christmas_keywords.items():
                filtered_data = self._filter_data_by_keywords(gsc_data, keywords)
                if not filtered_data.empty:
                    christmas_data[category] = filtered_data
                    logger.info(f"{category}: {len(filtered_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
            
            return christmas_data
            
        except Exception as e:
            logger.error(f"ã‚¯ãƒªã‚¹ãƒã‚¹GSCãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return christmas_data
    
    def _get_custom_gsc_data(self, start_date: str, end_date: str, 
                           dimensions: List[str] = None, row_limit: int = 25000) -> pd.DataFrame:
        """
        ã‚«ã‚¹ã‚¿ãƒ æ—¥ä»˜ç¯„å›²ã§GSCãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Args:
            start_date (str): é–‹å§‹æ—¥ (YYYY-MM-DD)
            end_date (str): çµ‚äº†æ—¥ (YYYY-MM-DD)
            dimensions (list): å–å¾—ã™ã‚‹ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³
            row_limit (int): å–å¾—è¡Œæ•°ä¸Šé™
        
        Returns:
            pd.DataFrame: GSCãƒ‡ãƒ¼ã‚¿
        """
        if not self.api_integration.gsc_service:
            logger.error("GSCã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return pd.DataFrame()
        
        if not dimensions:
            dimensions = ['date', 'query', 'page', 'country', 'device']
        
        try:
            # GSCãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
            request = {
                'startDate': start_date,
                'endDate': end_date,
                'dimensions': dimensions,
                'rowLimit': row_limit,
                'startRow': 0
            }
            
            # APIå‘¼ã³å‡ºã—
            response = self.api_integration.gsc_service.searchanalytics().query(
                siteUrl=self.api_integration.gsc_site_url,
                body=request
            ).execute()
            
            # ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
            data = []
            if 'rows' in response:
                for row in response['rows']:
                    row_data = {
                        'clicks': row.get('clicks', 0),
                        'impressions': row.get('impressions', 0),
                        'ctr': row.get('ctr', 0),
                        'position': row.get('position', 0)
                    }
                    
                    # ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å€¤ã®è¿½åŠ 
                    for i, dimension in enumerate(dimensions):
                        if i < len(row.get('keys', [])):
                            row_data[dimension] = row['keys'][i]
                    
                    data.append(row_data)
            
            df = pd.DataFrame(data)
            logger.info(f"GSCãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(df)}è¡Œ ({start_date} - {end_date})")
            return df
            
        except Exception as e:
            logger.error(f"GSCãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    def _filter_data_by_keywords(self, data: pd.DataFrame, keywords: List[str]) -> pd.DataFrame:
        """
        ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã§ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        
        Args:
            data (pd.DataFrame): ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ãƒ‡ãƒ¼ã‚¿
            keywords (list): ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        
        Returns:
            pd.DataFrame: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
        """
        if data.empty or 'query' not in data.columns:
            return pd.DataFrame()
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½œæˆ
        keyword_pattern = '|'.join(keywords)
        
        # ã‚¯ã‚¨ãƒªåˆ—ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_data = data[
            data['query'].str.contains(keyword_pattern, case=False, na=False)
        ].copy()
        
        return filtered_data
    
    def get_christmas_ga4_data(self) -> Dict[str, Any]:
        """
        ã‚¯ãƒªã‚¹ãƒã‚¹æœŸé–“ã®GA4ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Returns:
            Dict[str, Any]: GA4ãƒ‡ãƒ¼ã‚¿ã¨ã‚µãƒãƒªãƒ¼
        """
        logger.info("ã‚¯ãƒªã‚¹ãƒã‚¹æœŸé–“ã®GA4ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹")
        
        try:
            # ã‚«ã‚¹ã‚¿ãƒ æ—¥ä»˜ç¯„å›²ã§GA4ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            ga4_data = self._get_custom_ga4_data(
                start_date=self.report_period['start_date'],
                end_date=self.report_period['end_date']
            )
            
            if ga4_data.empty:
                logger.warning("GA4ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return {}
            
            # ã‚µãƒãƒªãƒ¼çµ±è¨ˆã®è¨ˆç®—
            summary = self._calculate_ga4_summary(ga4_data)
            
            # æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰ã®è¨ˆç®—
            daily_trends = self._calculate_daily_trends(ga4_data)
            
            # ãƒ‡ãƒã‚¤ã‚¹åˆ¥åˆ†æ
            device_analysis = self._analyze_by_device(ga4_data)
            
            # ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚½ãƒ¼ã‚¹åˆ†æ
            traffic_analysis = self._analyze_traffic_sources(ga4_data)
            
            return {
                'raw_data': ga4_data,
                'summary': summary,
                'daily_trends': daily_trends,
                'device_analysis': device_analysis,
                'traffic_analysis': traffic_analysis
            }
            
        except Exception as e:
            logger.error(f"ã‚¯ãƒªã‚¹ãƒã‚¹GA4ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _get_custom_ga4_data(self, start_date: str, end_date: str,
                           metrics: List[str] = None, dimensions: List[str] = None) -> pd.DataFrame:
        """
        ã‚«ã‚¹ã‚¿ãƒ æ—¥ä»˜ç¯„å›²ã§GA4ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Args:
            start_date (str): é–‹å§‹æ—¥ (YYYY-MM-DD)
            end_date (str): çµ‚äº†æ—¥ (YYYY-MM-DD)
            metrics (list): å–å¾—ã™ã‚‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            dimensions (list): å–å¾—ã™ã‚‹ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³
        
        Returns:
            pd.DataFrame: GA4ãƒ‡ãƒ¼ã‚¿
        """
        if not self.api_integration.ga4_service:
            logger.error("GA4ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return pd.DataFrame()
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹
        if not metrics:
            metrics = [
                'sessions', 'users', 'pageviews', 'bounceRate',
                'averageSessionDuration', 'conversions', 'totalRevenue'
            ]
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³
        if not dimensions:
            dimensions = [
                'date', 'pagePath', 'sourceMedium', 'deviceCategory', 'country'
            ]
        
        try:
            # GA4ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
            request = {
                'requests': [{
                    'property': f'properties/{self.api_integration.ga4_property_id}',
                    'dateRanges': [{'startDate': start_date, 'endDate': end_date}],
                    'metrics': [{'name': metric} for metric in metrics],
                    'dimensions': [{'name': dimension} for dimension in dimensions],
                    'limit': 100000
                }]
            }
            
            # APIå‘¼ã³å‡ºã—
            response = self.api_integration.ga4_service.properties().batchRunReports(
                property=f'properties/{self.api_integration.ga4_property_id}',
                body=request
            ).execute()
            
            # ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
            data = []
            if 'reports' in response:
                for report in response['reports']:
                    if 'rows' in report:
                        for row in report['rows']:
                            row_data = {}
                            
                            # ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å€¤ã®å–å¾—
                            for i, dimension in enumerate(dimensions):
                                if i < len(row.get('dimensionValues', [])):
                                    row_data[dimension] = row['dimensionValues'][i].get('value', '')
                            
                            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å€¤ã®å–å¾—
                            for i, metric in enumerate(metrics):
                                if i < len(row.get('metricValues', [])):
                                    value = row['metricValues'][i].get('value', '0')
                                    try:
                                        row_data[metric] = float(value)
                                    except ValueError:
                                        row_data[metric] = value
                            
                            data.append(row_data)
            
            df = pd.DataFrame(data)
            logger.info(f"GA4ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(df)}è¡Œ ({start_date} - {end_date})")
            return df
            
        except Exception as e:
            logger.error(f"GA4ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    def _calculate_ga4_summary(self, ga4_data: pd.DataFrame) -> Dict[str, Any]:
        """GA4ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒãƒªãƒ¼çµ±è¨ˆã‚’è¨ˆç®—"""
        if ga4_data.empty:
            return {}
        
        summary = {}
        
        # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        if 'sessions' in ga4_data.columns:
            summary['total_sessions'] = int(ga4_data['sessions'].sum())
        if 'users' in ga4_data.columns:
            summary['total_users'] = int(ga4_data['users'].sum())
        if 'pageviews' in ga4_data.columns:
            summary['total_pageviews'] = int(ga4_data['pageviews'].sum())
        if 'bounceRate' in ga4_data.columns:
            summary['avg_bounce_rate'] = float(ga4_data['bounceRate'].mean())
        if 'averageSessionDuration' in ga4_data.columns:
            summary['avg_session_duration'] = float(ga4_data['averageSessionDuration'].mean())
        if 'conversions' in ga4_data.columns:
            summary['total_conversions'] = int(ga4_data['conversions'].sum())
        if 'totalRevenue' in ga4_data.columns:
            summary['total_revenue'] = float(ga4_data['totalRevenue'].sum())
        
        return summary
    
    def _calculate_daily_trends(self, ga4_data: pd.DataFrame) -> pd.DataFrame:
        """æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¨ˆç®—"""
        if ga4_data.empty or 'date' not in ga4_data.columns:
            return pd.DataFrame()
        
        # æ—¥åˆ¥ã§é›†è¨ˆ
        daily_data = ga4_data.groupby('date').agg({
            'sessions': 'sum',
            'users': 'sum',
            'pageviews': 'sum',
            'bounceRate': 'mean',
            'averageSessionDuration': 'mean',
            'conversions': 'sum',
            'totalRevenue': 'sum'
        }).reset_index()
        
        # æ—¥ä»˜ã‚’datetimeã«å¤‰æ›
        daily_data['date'] = pd.to_datetime(daily_data['date'])
        
        return daily_data.sort_values('date')
    
    def _analyze_by_device(self, ga4_data: pd.DataFrame) -> pd.DataFrame:
        """ãƒ‡ãƒã‚¤ã‚¹åˆ¥åˆ†æ"""
        if ga4_data.empty or 'deviceCategory' not in ga4_data.columns:
            return pd.DataFrame()
        
        device_data = ga4_data.groupby('deviceCategory').agg({
            'sessions': 'sum',
            'users': 'sum',
            'pageviews': 'sum',
            'bounceRate': 'mean',
            'averageSessionDuration': 'mean',
            'conversions': 'sum',
            'totalRevenue': 'sum'
        }).reset_index()
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°ã§ã‚½ãƒ¼ãƒˆ
        return device_data.sort_values('sessions', ascending=False)
    
    def _analyze_traffic_sources(self, ga4_data: pd.DataFrame) -> pd.DataFrame:
        """ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚½ãƒ¼ã‚¹åˆ†æ"""
        if ga4_data.empty or 'sourceMedium' not in ga4_data.columns:
            return pd.DataFrame()
        
        traffic_data = ga4_data.groupby('sourceMedium').agg({
            'sessions': 'sum',
            'users': 'sum',
            'pageviews': 'sum',
            'bounceRate': 'mean',
            'averageSessionDuration': 'mean',
            'conversions': 'sum',
            'totalRevenue': 'sum'
        }).reset_index()
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°ã§ã‚½ãƒ¼ãƒˆ
        return traffic_data.sort_values('sessions', ascending=False)
    
    def analyze_christmas_keywords(self, gsc_data: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """
        ã‚¯ãƒªã‚¹ãƒã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è©³ç´°åˆ†æ
        
        Args:
            gsc_data (Dict[str, pd.DataFrame]): ã‚«ãƒ†ã‚´ãƒªåˆ¥GSCãƒ‡ãƒ¼ã‚¿
        
        Returns:
            Dict[str, Any]: åˆ†æçµæœ
        """
        logger.info("ã‚¯ãƒªã‚¹ãƒã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æé–‹å§‹")
        
        analysis = {
            'category_summary': {},
            'top_performing_keywords': {},
            'keyword_trends': {},
            'opportunities': []
        }
        
        try:
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚µãƒãƒªãƒ¼
            for category, data in gsc_data.items():
                if data.empty:
                    continue
                
                category_summary = {
                    'total_clicks': int(data['clicks'].sum()),
                    'total_impressions': int(data['impressions'].sum()),
                    'avg_ctr': float(data['ctr'].mean()),
                    'avg_position': float(data['position'].mean()),
                    'keyword_count': len(data)
                }
                
                analysis['category_summary'][category] = category_summary
                
                # ãƒˆãƒƒãƒ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                top_keywords = data.nlargest(10, 'clicks')[['query', 'clicks', 'impressions', 'ctr', 'position']]
                analysis['top_performing_keywords'][category] = top_keywords.to_dict('records')
            
            # æ©Ÿä¼šåˆ†æ
            analysis['opportunities'] = self._identify_opportunities(gsc_data)
            
            return analysis
            
        except Exception as e:
            logger.error(f"ã‚¯ãƒªã‚¹ãƒã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return analysis
    
    def _identify_opportunities(self, gsc_data: Dict[str, pd.DataFrame]) -> List[Dict[str, Any]]:
        """SEOæ©Ÿä¼šã®ç‰¹å®š"""
        opportunities = []
        
        try:
            for category, data in gsc_data.items():
                if data.empty:
                    continue
                
                # é«˜ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ»ä½CTRã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                high_imp_low_ctr = data[
                    (data['impressions'] > data['impressions'].quantile(0.75)) &
                    (data['ctr'] < data['ctr'].quantile(0.25))
                ]
                
                if not high_imp_low_ctr.empty:
                    opportunities.append({
                        'type': 'CTRæ”¹å–„æ©Ÿä¼š',
                        'category': category,
                        'keywords': high_imp_low_ctr.head(5)[['query', 'impressions', 'ctr', 'position']].to_dict('records'),
                        'description': f'{category}ã‚«ãƒ†ã‚´ãƒªã§CTRæ”¹å–„ã®æ©Ÿä¼šãŒã‚ã‚Šã¾ã™'
                    })
                
                # 10-20ä½ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                ranking_opportunities = data[
                    (data['position'] >= 10) & (data['position'] <= 20)
                ]
                
                if not ranking_opportunities.empty:
                    opportunities.append({
                        'type': 'é †ä½ä¸Šæ˜‡æ©Ÿä¼š',
                        'category': category,
                        'keywords': ranking_opportunities.head(5)[['query', 'clicks', 'position']].to_dict('records'),
                        'description': f'{category}ã‚«ãƒ†ã‚´ãƒªã§é †ä½ä¸Šæ˜‡ã®æ©Ÿä¼šãŒã‚ã‚Šã¾ã™'
                    })
            
            return opportunities
            
        except Exception as e:
            logger.error(f"æ©Ÿä¼šåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return opportunities
    
    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """
        åŒ…æ‹¬çš„ãªã‚¯ãƒªã‚¹ãƒã‚¹ã‚·ãƒ¼ã‚ºãƒ³ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        
        Returns:
            Dict[str, Any]: åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆ
        """
        logger.info("åŒ…æ‹¬çš„ã‚¯ãƒªã‚¹ãƒã‚¹ã‚·ãƒ¼ã‚ºãƒ³ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿å–å¾—
            gsc_data = self.get_christmas_gsc_data()
            ga4_data = self.get_christmas_ga4_data()
            
            # åˆ†æå®Ÿè¡Œ
            keyword_analysis = self.analyze_christmas_keywords(gsc_data)
            
            # ãƒ¬ãƒãƒ¼ãƒˆçµ±åˆ
            comprehensive_report = {
                'report_metadata': {
                    'title': '2024å¹´ã‚¯ãƒªã‚¹ãƒã‚¹ã‚·ãƒ¼ã‚ºãƒ³ãƒ¬ãƒãƒ¼ãƒˆ',
                    'period': f"{self.report_period['start_date']} - {self.report_period['end_date']}",
                    'generated_at': datetime.now().isoformat(),
                    'site_url': self.api_integration.gsc_site_url
                },
                'gsc_data': gsc_data,
                'ga4_data': ga4_data,
                'keyword_analysis': keyword_analysis,
                'recommendations': self._generate_recommendations(keyword_analysis, ga4_data)
            }
            
            # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
            self._save_report(comprehensive_report)
            
            logger.info("åŒ…æ‹¬çš„ã‚¯ãƒªã‚¹ãƒã‚¹ã‚·ãƒ¼ã‚ºãƒ³ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")
            return comprehensive_report
            
        except Exception as e:
            logger.error(f"åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _generate_recommendations(self, keyword_analysis: Dict[str, Any], 
                                ga4_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ¨å¥¨äº‹é …ã®ç”Ÿæˆ"""
        recommendations = []
        
        try:
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã‹ã‚‰ã®æ¨å¥¨äº‹é …
            for category, summary in keyword_analysis.get('category_summary', {}).items():
                if summary['avg_position'] > 15:
                    recommendations.append({
                        'type': 'SEOæ”¹å–„',
                        'priority': 'high',
                        'category': category,
                        'message': f'{category}ã‚«ãƒ†ã‚´ãƒªã®å¹³å‡é †ä½ãŒ{summary["avg_position"]:.1f}ä½ã§ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æœ€é©åŒ–ãŒå¿…è¦ã§ã™ã€‚'
                    })
                
                if summary['avg_ctr'] < 2.0:
                    recommendations.append({
                        'type': 'CTRæ”¹å–„',
                        'priority': 'medium',
                        'category': category,
                        'message': f'{category}ã‚«ãƒ†ã‚´ãƒªã®CTRãŒ{summary["avg_ctr"]:.2f}%ã§ã™ã€‚ã‚¿ã‚¤ãƒˆãƒ«æœ€é©åŒ–ãŒå¿…è¦ã§ã™ã€‚'
                    })
            
            # GA4ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®æ¨å¥¨äº‹é …
            if 'summary' in ga4_data:
                summary = ga4_data['summary']
                if summary.get('avg_bounce_rate', 0) > 0.7:
                    recommendations.append({
                        'type': 'UXæ”¹å–„',
                        'priority': 'high',
                        'message': f'ãƒã‚¦ãƒ³ã‚¹ç‡ãŒ{summary["avg_bounce_rate"]:.2%}ã¨é«˜ã™ãã¾ã™ã€‚ãƒšãƒ¼ã‚¸æ”¹å–„ãŒå¿…è¦ã§ã™ã€‚'
                    })
            
            return recommendations
            
        except Exception as e:
            logger.error(f"æ¨å¥¨äº‹é …ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return recommendations
    
    def _save_report(self, report: Dict[str, Any]):
        """ãƒ¬ãƒãƒ¼ãƒˆã®ä¿å­˜"""
        try:
            # JSONå½¢å¼ã§ä¿å­˜
            report_file = f'data/christmas_2024/christmas_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2, default=str)
            
            # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚‚ç”Ÿæˆ
            self._generate_summary_markdown(report)
            
            logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†: {report_file}")
            
        except Exception as e:
            logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _generate_summary_markdown(self, report: Dict[str, Any]):
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®Markdownç”Ÿæˆ"""
        try:
            markdown_content = self._format_report_as_markdown(report)
            
            markdown_file = f'data/christmas_2024/christmas_summary_{datetime.now().strftime("%Y%m%d_%H%M%S")}.md'
            with open(markdown_file, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
            
            logger.info(f"ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†: {markdown_file}")
            
        except Exception as e:
            logger.error(f"ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def _format_report_as_markdown(self, report: Dict[str, Any]) -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’Markdownå½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        metadata = report.get('report_metadata', {})
        ga4_data = report.get('ga4_data', {})
        keyword_analysis = report.get('keyword_analysis', {})
        recommendations = report.get('recommendations', [])
        
        content = f"""# {metadata.get('title', 'ã‚¯ãƒªã‚¹ãƒã‚¹ã‚·ãƒ¼ã‚ºãƒ³ãƒ¬ãƒãƒ¼ãƒˆ')}

**æœŸé–“**: {metadata.get('period', 'N/A')}  
**ç”Ÿæˆæ—¥æ™‚**: {metadata.get('generated_at', 'N/A')}  
**ã‚µã‚¤ãƒˆURL**: {metadata.get('site_url', 'N/A')}

## ğŸ“Š æ¦‚è¦

### GA4ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
"""
        
        # GA4ã‚µãƒãƒªãƒ¼
        if 'summary' in ga4_data:
            summary = ga4_data['summary']
            content += f"""
- **ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°**: {summary.get('total_sessions', 0):,}
- **ç·ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°**: {summary.get('total_users', 0):,}
- **ç·ãƒšãƒ¼ã‚¸ãƒ“ãƒ¥ãƒ¼**: {summary.get('total_pageviews', 0):,}
- **å¹³å‡ãƒã‚¦ãƒ³ã‚¹ç‡**: {summary.get('avg_bounce_rate', 0):.2%}
- **å¹³å‡ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“**: {summary.get('avg_session_duration', 0):.1f}ç§’
- **ç·ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°**: {summary.get('total_conversions', 0):,}
- **ç·åç›Š**: Â¥{summary.get('total_revenue', 0):,.0f}
"""
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
        content += "\n## ğŸ” ã‚¯ãƒªã‚¹ãƒã‚¹é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ\n"
        
        for category, summary in keyword_analysis.get('category_summary', {}).items():
            content += f"""
### {category.replace('_', ' ').title()}
- **ç·ã‚¯ãƒªãƒƒã‚¯æ•°**: {summary.get('total_clicks', 0):,}
- **ç·ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°**: {summary.get('total_impressions', 0):,}
- **å¹³å‡CTR**: {summary.get('avg_ctr', 0):.2f}%
- **å¹³å‡é †ä½**: {summary.get('avg_position', 0):.1f}ä½
- **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°**: {summary.get('keyword_count', 0)}å€‹
"""
        
        # æ¨å¥¨äº‹é …
        if recommendations:
            content += "\n## ğŸ’¡ æ¨å¥¨äº‹é …\n"
            for i, rec in enumerate(recommendations, 1):
                priority_emoji = "ğŸ”´" if rec.get('priority') == 'high' else "ğŸŸ¡"
                content += f"{i}. {priority_emoji} **{rec.get('type', 'N/A')}**: {rec.get('message', 'N/A')}\n"
        
        content += f"""
## ğŸ“ˆ ä»Šå¾Œã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

1. **é«˜å„ªå…ˆåº¦ã®SEOæ”¹å–„**ã‚’å®Ÿæ–½
2. **CTRæ”¹å–„**ã®ãŸã‚ã®ã‚¿ã‚¤ãƒˆãƒ«æœ€é©åŒ–
3. **ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“å‘ä¸Š**ã®ãŸã‚ã®ãƒšãƒ¼ã‚¸æ”¹å–„
4. **å®šæœŸç›£è¦–**ã«ã‚ˆã‚‹ç¶™ç¶šçš„ãªæ”¹å–„

---
*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚è©³ç´°ãªåˆ†æãƒ‡ãƒ¼ã‚¿ã¯JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã”ç¢ºèªãã ã•ã„ã€‚*
"""
        
        return content

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=== 2024å¹´ã‚¯ãƒªã‚¹ãƒã‚¹ã‚·ãƒ¼ã‚ºãƒ³ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹ ===")
    
    # ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª
    required_env_vars = ['GA4_PROPERTY_ID', 'GSC_SITE_URL']
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        print(f"ä»¥ä¸‹ã®ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“: {', '.join(missing_vars)}")
        print("è¨­å®šä¾‹:")
        print("export GA4_PROPERTY_ID='316302380'")
        print("export GSC_SITE_URL='https://isetan.mistore.jp/moodmarkgift/'")
        return
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå™¨ã®åˆæœŸåŒ–
    report_generator = ChristmasSeasonReportGenerator('config/google-credentials.json')
    
    # åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = report_generator.generate_comprehensive_report()
    
    if report:
        print("\n=== ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº† ===")
        print(f"ãƒ¬ãƒãƒ¼ãƒˆæœŸé–“: {report['report_metadata']['period']}")
        print(f"ç”Ÿæˆæ—¥æ™‚: {report['report_metadata']['generated_at']}")
        
        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        if 'ga4_data' in report and 'summary' in report['ga4_data']:
            summary = report['ga4_data']['summary']
            print(f"\n--- GA4ã‚µãƒãƒªãƒ¼ ---")
            print(f"ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {summary.get('total_sessions', 0):,}")
            print(f"ç·ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {summary.get('total_users', 0):,}")
            print(f"ç·ãƒšãƒ¼ã‚¸ãƒ“ãƒ¥ãƒ¼: {summary.get('total_pageviews', 0):,}")
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚µãƒãƒªãƒ¼
        if 'keyword_analysis' in report and 'category_summary' in report['keyword_analysis']:
            print(f"\n--- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚µãƒãƒªãƒ¼ ---")
            for category, cat_summary in report['keyword_analysis']['category_summary'].items():
                print(f"{category}: {cat_summary.get('total_clicks', 0):,}ã‚¯ãƒªãƒƒã‚¯")
        
        # æ¨å¥¨äº‹é …
        if 'recommendations' in report and report['recommendations']:
            print(f"\n--- æ¨å¥¨äº‹é … ---")
            for i, rec in enumerate(report['recommendations'][:5], 1):
                print(f"{i}. {rec.get('message', 'N/A')}")
        
        print(f"\nè©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã¯ data/christmas_2024/ ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
    else:
        print("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()
