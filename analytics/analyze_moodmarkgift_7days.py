#!/usr/bin/env python3
"""
MOO:D MARK GIFTï¼ˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„SEOãƒ¡ãƒ‡ã‚£ã‚¢ï¼‰ã®ç›´è¿‘7æ—¥é–“åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ­£ç¢ºãªæ¸¬å®šæ–¹æ³•ï¼š
- ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: landingPageãƒ™ãƒ¼ã‚¹
- ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: activeUsers
- PVæ•°: pagePathãƒ™ãƒ¼ã‚¹
- ç›´å¸°ç‡ãƒ»ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“: å…¨ã‚µã‚¤ãƒˆå…±é€šï¼ˆåˆ†é›¢ä¸å¯ï¼‰
"""

import sys
import os
import json
import pandas as pd
from datetime import datetime, timedelta
from oauth_google_apis import OAuthGoogleAPIsIntegration

def analyze_moodmarkgift_7days():
    """moodmarkgiftã‚µã‚¤ãƒˆã®ç›´è¿‘7æ—¥é–“ã®è©³ç´°åˆ†æã‚’å®Ÿè¡Œ"""
    
    print("\n" + "=" * 70)
    print("  MOO:D MARK GIFT ã‚µã‚¤ãƒˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ - ç›´è¿‘7æ—¥é–“")
    print("  https://isetan.mistore.jp/moodmarkgift/")
    print("  ã‚³ãƒ³ãƒ†ãƒ³ãƒ„SEOãƒ¡ãƒ‡ã‚£ã‚¢")
    print("=" * 70)
    
    # APIåˆæœŸåŒ–
    api = OAuthGoogleAPIsIntegration()
    
    if not api.credentials:
        print("\nâŒ èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...\n")
    
    property_id = "316302380"
    
    # 1. ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ï¼ˆlandingPageãƒ™ãƒ¼ã‚¹ï¼‰
    print("1ï¸âƒ£  æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ")
    print("-" * 70)
    
    session_data = api.get_ga4_data(
        date_range_days=7,
        metrics=['sessions', 'activeUsers', 'engagementRate', 'newUsers'],
        dimensions=['date', 'landingPage'],
        property_id=property_id
    )
    
    # PVæ•°ï¼ˆpagePathãƒ™ãƒ¼ã‚¹ï¼‰
    pv_data = api.get_ga4_data(
        date_range_days=7,
        metrics=['screenPageViews'],
        dimensions=['date', 'pagePath'],
        property_id=property_id
    )
    
    if not session_data.empty and not pv_data.empty:
        # SEOãƒ¡ãƒ‡ã‚£ã‚¢ã§ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã—ãŸã‚»ãƒƒã‚·ãƒ§ãƒ³
        gift_session_data = session_data[
            session_data['landingPage'].str.contains('/moodmarkgift/', na=False)
        ]
        
        # SEOãƒ¡ãƒ‡ã‚£ã‚¢ã®PV
        gift_pv_data = pv_data[
            pv_data['pagePath'].str.contains('/moodmarkgift/', na=False)
        ]
        
        if not gift_session_data.empty and not gift_pv_data.empty:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼é›†è¨ˆ
            session_summary = gift_session_data.groupby('date').agg({
                'sessions': 'sum',
                'activeUsers': 'sum',
                'engagementRate': 'mean',
                'newUsers': 'sum'
            }).reset_index()
            
            # PVé›†è¨ˆ
            pv_summary = gift_pv_data.groupby('date').agg({
                'screenPageViews': 'sum'
            }).reset_index()
            
            # ãƒãƒ¼ã‚¸
            daily_summary = session_summary.merge(pv_summary, on='date', how='left')
            daily_summary['screenPageViews'] = daily_summary['screenPageViews'].fillna(0)
            daily_summary = daily_summary.sort_values('date')
            
            print(daily_summary.to_string(index=False))
            
            # åˆè¨ˆå€¤
            print("\nğŸ“ˆ 7æ—¥é–“ã®åˆè¨ˆ:")
            print(f"   ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {daily_summary['sessions'].sum():,.0f}")
            print(f"   ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {daily_summary['activeUsers'].sum():,.0f}")
            print(f"   ç·ãƒšãƒ¼ã‚¸ãƒ“ãƒ¥ãƒ¼æ•°: {daily_summary['screenPageViews'].sum():,.0f}")
            print(f"   æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {daily_summary['newUsers'].sum():,.0f}")
            
            # å¹³å‡å€¤
            print(f"\nğŸ“Š 7æ—¥é–“ã®å¹³å‡:")
            print(f"   å¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡: {daily_summary['engagementRate'].mean():.1%}")
            print(f"   æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¯”ç‡: {(daily_summary['newUsers'].sum() / daily_summary['activeUsers'].sum() * 100):.1f}%")
            print(f"   PV/ã‚»ãƒƒã‚·ãƒ§ãƒ³: {daily_summary['screenPageViews'].sum() / daily_summary['sessions'].sum():.2f}")
        else:
            print("âš ï¸ moodmarkgiftã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            daily_summary = pd.DataFrame()
    else:
        daily_summary = pd.DataFrame()
    
    # 2. ãƒ‡ãƒã‚¤ã‚¹åˆ¥åˆ†æ
    print("\n\n2ï¸âƒ£  ãƒ‡ãƒã‚¤ã‚¹åˆ¥åˆ†æ")
    print("-" * 70)
    
    device_session_data = api.get_ga4_data(
        date_range_days=7,
        metrics=['sessions', 'activeUsers', 'engagementRate'],
        dimensions=['deviceCategory', 'landingPage'],
        property_id=property_id
    )
    
    if not device_session_data.empty:
        gift_device_session = device_session_data[
            device_session_data['landingPage'].str.contains('/moodmarkgift/', na=False)
        ]
        
        if not gift_device_session.empty:
            device_summary = gift_device_session.groupby('deviceCategory').agg({
                'sessions': 'sum',
                'activeUsers': 'sum',
                'engagementRate': 'mean'
            }).reset_index()
            
            device_summary['session_share'] = (device_summary['sessions'] / device_summary['sessions'].sum() * 100).round(1)
            device_summary = device_summary.sort_values('sessions', ascending=False)
            
            print(device_summary.to_string(index=False))
        else:
            device_summary = pd.DataFrame()
    else:
        device_summary = pd.DataFrame()
    
    # 3. ãƒãƒ£ãƒãƒ«åˆ¥åˆ†æ
    print("\n\n3ï¸âƒ£  ãƒãƒ£ãƒãƒ«åˆ¥åˆ†æï¼ˆæµå…¥å…ƒï¼‰")
    print("-" * 70)
    
    channel_data = api.get_ga4_data(
        date_range_days=7,
        metrics=['sessions', 'activeUsers', 'engagementRate', 'newUsers'],
        dimensions=['sessionDefaultChannelGrouping', 'landingPage'],
        property_id=property_id
    )
    
    if not channel_data.empty:
        gift_channel_data = channel_data[
            channel_data['landingPage'].str.contains('/moodmarkgift/', na=False)
        ]
        
        if not gift_channel_data.empty:
            channel_summary = gift_channel_data.groupby('sessionDefaultChannelGrouping').agg({
                'sessions': 'sum',
                'activeUsers': 'sum',
                'engagementRate': 'mean',
                'newUsers': 'sum'
            }).reset_index()
            
            channel_summary['session_share'] = (channel_summary['sessions'] / channel_summary['sessions'].sum() * 100).round(1)
            channel_summary = channel_summary.sort_values('sessions', ascending=False)
            
            print(channel_summary.to_string(index=False))
        else:
            channel_summary = pd.DataFrame()
    else:
        channel_summary = pd.DataFrame()
    
    # 4. äººæ°—ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æï¼ˆpagePathãƒ™ãƒ¼ã‚¹ï¼‰
    print("\n\n4ï¸âƒ£  äººæ°—ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ TOP20ï¼ˆè¨˜äº‹ãƒ»ãƒšãƒ¼ã‚¸ï¼‰")
    print("-" * 70)
    
    page_data = api.get_ga4_data(
        date_range_days=7,
        metrics=['screenPageViews', 'sessions'],
        dimensions=['pagePath', 'pageTitle'],
        property_id=property_id
    )
    
    if not page_data.empty:
        gift_page_data = page_data[
            page_data['pagePath'].str.contains('/moodmarkgift/', na=False)
        ]
        
        if not gift_page_data.empty:
            page_summary = gift_page_data.groupby(['pagePath', 'pageTitle']).agg({
                'screenPageViews': 'sum',
                'sessions': 'sum'
            }).reset_index()
            
            page_summary = page_summary.sort_values('screenPageViews', ascending=False).head(20)
            
            for idx, row in page_summary.iterrows():
                print(f"\n{idx+1}. {row['pageTitle']}")
                print(f"   URL: {row['pagePath']}")
                print(f"   PV: {row['screenPageViews']:,.0f} | ã‚»ãƒƒã‚·ãƒ§ãƒ³: {row['sessions']:,.0f}")
        else:
            page_summary = pd.DataFrame()
    else:
        page_summary = pd.DataFrame()
    
    # 5. æ™‚é–“å¸¯åˆ¥åˆ†æ
    print("\n\n5ï¸âƒ£  æ™‚é–“å¸¯åˆ¥ã‚¢ã‚¯ã‚»ã‚¹åˆ†æ")
    print("-" * 70)
    
    hourly_data = api.get_ga4_data(
        date_range_days=7,
        metrics=['sessions', 'activeUsers'],
        dimensions=['dateHour', 'landingPage'],
        property_id=property_id
    )
    
    if not hourly_data.empty:
        gift_hourly_data = hourly_data[
            hourly_data['landingPage'].str.contains('/moodmarkgift/', na=False)
        ].copy()
        
        if not gift_hourly_data.empty:
            gift_hourly_data['hour'] = gift_hourly_data['dateHour'].astype(str).str[-2:].astype(int)
            
            hourly_summary = gift_hourly_data.groupby('hour').agg({
                'sessions': 'sum',
                'activeUsers': 'sum'
            }).reset_index()
            
            hourly_summary = hourly_summary.sort_values('sessions', ascending=False).head(10)
            print("ã‚¢ã‚¯ã‚»ã‚¹ãŒå¤šã„æ™‚é–“å¸¯ TOP10:")
            print(hourly_summary.to_string(index=False))
        else:
            hourly_summary = pd.DataFrame()
    else:
        hourly_summary = pd.DataFrame()
    
    # 6. å…¨ã‚µã‚¤ãƒˆå…±é€šæŒ‡æ¨™
    print("\n\n6ï¸âƒ£  å…¨ã‚µã‚¤ãƒˆå…±é€šæŒ‡æ¨™ï¼ˆå‚è€ƒå€¤ï¼‰")
    print("-" * 70)
    print("â€» ç›´å¸°ç‡ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“ã¯ä¸¡ã‚µã‚¤ãƒˆãŒåŒã˜ãƒ‰ãƒ¡ã‚¤ãƒ³å†…ã«ã‚ã‚‹ãŸã‚ã€")
    print("  ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã§ã¯æ­£ç¢ºã«åˆ†é›¢ã§ãã¾ã›ã‚“ã€‚")
    
    overall_data = api.get_ga4_data(
        date_range_days=7,
        metrics=['sessions', 'bounceRate', 'averageSessionDuration'],
        dimensions=['date'],
        property_id=property_id
    )
    
    if not overall_data.empty:
        print(f"\nå…¨ã‚µã‚¤ãƒˆå¹³å‡:")
        print(f"   å¹³å‡ç›´å¸°ç‡: {overall_data['bounceRate'].mean():.1%}")
        print(f"   å¹³å‡ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“: {overall_data['averageSessionDuration'].mean():.0f}ç§’ï¼ˆ{overall_data['averageSessionDuration'].mean()/60:.1f}åˆ†ï¼‰")
    
    # 7. SEOãƒ¡ãƒ‡ã‚£ã‚¢ã¨ã—ã¦ã®è©•ä¾¡
    print("\n\n7ï¸âƒ£  SEOãƒ¡ãƒ‡ã‚£ã‚¢ã¨ã—ã¦ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡")
    print("-" * 70)
    
    recommendations = []
    
    if not daily_summary.empty:
        total_sessions = daily_summary['sessions'].sum()
        new_users = daily_summary['newUsers'].sum()
        active_users = daily_summary['activeUsers'].sum()
        new_user_rate = (new_users / active_users * 100)
        
        print(f"\nğŸ“Š åŸºæœ¬æŒ‡æ¨™:")
        print(f"   â€¢ ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {total_sessions:,.0f}")
        print(f"   â€¢ æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ç‡: {new_user_rate:.1f}%")
        
        if new_user_rate > 70:
            print(f"\nâœ… æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ç²å¾—ãŒè‰¯å¥½ã§ã™ï¼ˆ{new_user_rate:.1f}%ï¼‰")
            recommendations.append("æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ç²å¾—ãŒé †èª¿ã§ã™ã€‚æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªãƒ”ãƒ¼ãƒˆæ–½ç­–ã‚‚æ¤œè¨ã—ã¾ã—ã‚‡ã†ã€‚")
    
    if not channel_summary.empty:
        organic_sessions = channel_summary[channel_summary['sessionDefaultChannelGrouping'] == 'Organic Search']['sessions'].sum()
        total_channel_sessions = channel_summary['sessions'].sum()
        organic_rate = (organic_sessions / total_channel_sessions * 100)
        
        print(f"\nğŸ” æµå…¥å…ƒåˆ†æ:")
        print(f"   â€¢ è‡ªç„¶æ¤œç´¢æ¯”ç‡: {organic_rate:.1f}%")
        
        if organic_rate > 70:
            print(f"âœ… SEOãƒ¡ãƒ‡ã‚£ã‚¢ã¨ã—ã¦å„ªç§€ã§ã™ï¼ˆè‡ªç„¶æ¤œç´¢{organic_rate:.1f}%ï¼‰")
            recommendations.append("SEOå¯¾ç­–ãŒåŠ¹æœçš„ã§ã™ã€‚å¼•ãç¶šãè³ªã®é«˜ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆã‚’ç¶™ç¶šã—ã¦ãã ã•ã„ã€‚")
    
    if not device_summary.empty:
        mobile_sessions = device_summary[device_summary['deviceCategory'] == 'mobile']['sessions'].sum()
        total_device_sessions = device_summary['sessions'].sum()
        mobile_rate = (mobile_sessions / total_device_sessions * 100)
        
        print(f"\nğŸ“± ãƒ‡ãƒã‚¤ã‚¹æ§‹æˆ:")
        print(f"   â€¢ ãƒ¢ãƒã‚¤ãƒ«æ¯”ç‡: {mobile_rate:.1f}%")
        
        if mobile_rate > 70:
            recommendations.append("ãƒ¢ãƒã‚¤ãƒ«èª­è€…ãŒå¤šã„ãŸã‚ã€ãƒ¢ãƒã‚¤ãƒ«ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¨­è¨ˆã‚’ç¶™ç¶šã—ã¦ãã ã•ã„ã€‚")
    
    if recommendations:
        print(f"\n\nğŸ’¡ æ¨å¥¨äº‹é …:")
        for i, rec in enumerate(recommendations, 1):
            print(f"   {i}. {rec}")
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    print("\n\n8ï¸âƒ£  ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜")
    print("-" * 70)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    os.makedirs('data/processed', exist_ok=True)
    
    if not daily_summary.empty:
        daily_summary.to_csv(f'data/processed/moodmarkgift_daily_trend_7days_{timestamp}.csv', index=False, encoding='utf-8-sig')
        print(f"âœ… æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰: data/processed/moodmarkgift_daily_trend_7days_{timestamp}.csv")
    
    if not device_summary.empty:
        device_summary.to_csv(f'data/processed/moodmarkgift_device_analysis_7days_{timestamp}.csv', index=False, encoding='utf-8-sig')
        print(f"âœ… ãƒ‡ãƒã‚¤ã‚¹åˆ¥åˆ†æ: data/processed/moodmarkgift_device_analysis_7days_{timestamp}.csv")
    
    if not channel_summary.empty:
        channel_summary.to_csv(f'data/processed/moodmarkgift_channel_analysis_7days_{timestamp}.csv', index=False, encoding='utf-8-sig')
        print(f"âœ… ãƒãƒ£ãƒãƒ«åˆ¥åˆ†æ: data/processed/moodmarkgift_channel_analysis_7days_{timestamp}.csv")
    
    if not page_summary.empty:
        page_summary.to_csv(f'data/processed/moodmarkgift_top_pages_7days_{timestamp}.csv', index=False, encoding='utf-8-sig')
        print(f"âœ… äººæ°—ã‚³ãƒ³ãƒ†ãƒ³ãƒ„: data/processed/moodmarkgift_top_pages_7days_{timestamp}.csv")
    
    # JSONå½¢å¼ã§ã‚‚ä¿å­˜
    report = {
        'report_date': datetime.now().isoformat(),
        'period': 'ç›´è¿‘7æ—¥é–“',
        'site_url': 'https://isetan.mistore.jp/moodmarkgift/',
        'site_type': 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„SEOãƒ¡ãƒ‡ã‚£ã‚¢',
        'summary': {
            'total_sessions': int(daily_summary['sessions'].sum()) if not daily_summary.empty else 0,
            'active_users': int(daily_summary['activeUsers'].sum()) if not daily_summary.empty else 0,
            'total_pageviews': int(daily_summary['screenPageViews'].sum()) if not daily_summary.empty else 0,
            'new_users': int(daily_summary['newUsers'].sum()) if not daily_summary.empty else 0,
            'avg_engagement_rate': float(daily_summary['engagementRate'].mean()) if not daily_summary.empty else 0,
            'new_user_rate': float((daily_summary['newUsers'].sum() / daily_summary['activeUsers'].sum() * 100)) if not daily_summary.empty else 0,
            'pages_per_session': float(daily_summary['screenPageViews'].sum() / daily_summary['sessions'].sum()) if not daily_summary.empty else 0
        },
        'recommendations': recommendations,
        'note': 'ç›´å¸°ç‡ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“ã¯ä¸¡ã‚µã‚¤ãƒˆãŒåŒã˜ãƒ‰ãƒ¡ã‚¤ãƒ³å†…ã«ã‚ã‚‹ãŸã‚ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã§ã¯æ­£ç¢ºã«åˆ†é›¢ã§ãã¾ã›ã‚“ã€‚'
    }
    
    report_file = f'data/processed/moodmarkgift_analysis_report_7days_{timestamp}.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
    
    print("\n" + "=" * 70)
    print("  åˆ†æå®Œäº†ï¼")
    print("=" * 70 + "\n")
    
    return report

if __name__ == "__main__":
    analyze_moodmarkgift_7days()
